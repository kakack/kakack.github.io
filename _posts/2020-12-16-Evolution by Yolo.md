---

layout: post
categories: [Algorithm]
tags: [Detection, Deep Learning]

---

# Abstract

对于图像中目标检测，最朴素的需求就是输入一张目标图像，输出图像中待检测目标物的位置，用bounding box形式输出，和该物体的类别，用类别标签标示。在Yolo出现之前，业界最优秀的方法是基于region proposal的R-cnn系列方法，包括rcnn、fast-rcnn和faster-rcnn。概括而言这一类的算法可以归纳成两步走的two-stage，首先通过经验手段或者elective search、rpn等方法来生成网络觉得可能会出现目标物体位置的region proposal，然后再将rp中提取到的信息通过网络，最后用分类来获得目标物体的类别，用回归来确定目标物体的bounding box位置。这种做法相对于之前其他的方法而言，大大提高了物体定位的准确率，但是也存在一个很大的问题就是处理速度慢。人们举过一个很生动的例子，如果将rcnn系列检测器放在一辆以60km/h疾驰的汽车上做物体检测，当输入一帧画面得到结果的时候，用rcnn的车子已经开出300m远，用fast-rcnn的也已经开出34m以上。因此rcnn系列算法在一些强调响应速度的应用上，会显得非常滞后。

因此，yolo在设计之初的理念就是加快这个方法的运行速度。因此它摒弃了预先生成rp的方法，直接以整图作为模型的输入，提取整图的特征信息。然后在输出的时候不再对分类结果和定位结果分别处理，而是使用回归的方法一次性统一得到位置信息bounding box和分类信息class label。最后，yolo整体上设计的是一个端到端的单独网络，简化了训练和推理过程中的复杂度。整个流程可以概括为得到输入图像，resize成输入尺寸，经过卷积神经网络得到一系列输出，再使用一些阈值方法得到我们最终希望得到的检测结果。它不需要像原先的滑动窗口或者rpn算法一样反复在图片上遍历，而只需要看图片一次就够了，这也是yolo名字的来源，`you only look once`。

# How does Yolo work

