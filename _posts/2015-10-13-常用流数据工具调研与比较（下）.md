---

layout: post
categories: [Big Data]
tags: [Big Data, Distributed System, Spark Streaming, Storm]

---
#常用流数据工具调研与比较(下)

本文以详细介绍Apache Storm和Spark Streaming为主。

- - -

##关于Storm

总体要求：低延迟、高性能、分布式、可扩展、高容错，同时保证消息不丢失而有序

主要应用模式：

- **信息流处理（Stream processing）**：Storm可用来实时处理新数据和更新数据库，兼具容错性和可扩展性。

- **连续计算（Continuous computation）**：Storm可进行连续查询并把结果即时反馈给客户端。比如把Twitter上的热门话题发送到浏览器中。

- **分布式远程程序调用（Distributed RPC）**：Storm可用来并行处理密集查询。Storm的拓扑结构是一个等待调用信息的分布函数，当它收到一条调用信息后，会对查询进行计算，并返回查询结果。  举个例子Distributed RPC可以做并行搜索或者处理大集合的数据。

集群组成部分：

- **Tuple**：是一个通用的数据容器，支持一些基本数据类型和自定义类型，是形成数据流的最基本单位。由spout节点生成，交由bolt节点来处理转换并输出。

- **计算拓扑（Topologies）**：可以理解为Hadoop中的MapReduce Job，但是区别是MRJ在任务完成之后就会消失，而Topologies则会一直存在直到主动被kill。在一个计算拓扑中，封装了一个实时计算的应用程序逻辑。一个Topology是Spouts和Bolts组成的图状结构， 而链接Spouts和Bolts的则是Stream groupings。在默认状态下，Storm会安排尽量均匀数目的计算拓扑来负责计算处理。

- **消息流（Stream）**：一个消息流就是一个没有边界的tuple序列，其中的tuple会以分布式的形式被创建和处理，这些tuple会被用特定的名称来描述其中的字段，对于不同的tuple相同的字段都必须类型一致，就像是关系型数据库中的表的一条记录一样。

- **消息源（Spout）**：计算拓扑中消息的生产者，通常会从外部读取数据并作为tuple发送。消息发送的可靠性是自定义的。

- **消息处理者（Bolt）**：所有消息的处理逻辑都被封装在处理者中，如过滤、聚合、数据查询等。 一般的流程是： Bolts处理一个输入tuple,  发射0个或者多个tuple, 然后调用ack通知storm自己已经处理过这个tuple了。

- **消息分发策略（Stream Groups）**：定义一个Topology的其中一步是定义每个bolt接受什么样的流作为输入。每个Spout和Bolt都会被当做若干个tasks在集群中运行，task对应的是线程，stream grouping就是用来定义一个stream应该如何分配给Bolts上面的多个Tasks。总体来说，有六种不同类型的分发策略：

	1. *Shuffle Grouping*: 随机分组， 随机派发stream里面的tuple， 保证每个bolt接收到的tuple数目相同。
	2. *Fields Grouping*：按字段分组， 比如按userid来分组， 具有同样userid的tuple会被分到相同的Bolts， 而不同的userid则会被分配到不同的Bolts。
	3. *All Grouping*： 广播发送， 对于每一个tuple， 所有的Bolts都会收到。
	4. *Global Grouping*: 全局分组， 这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task。
	5. *Non Grouping*: 不分组， 这个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果， 有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行。
	6. *Direct Grouping*: 直接分组,  这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过TopologyContext来获取处理它的消息的taskid (OutputCollector.emit方法也会返回taskid)

![](https://raw.githubusercontent.com/kkkelsey/kkkelsey.github.io/master/_images/storm-concepts.png)

Storm整个架构保证了较高的可靠性，在每一个tuple被发送出来之后，Storm会追踪确保每个tuple被topology完整地被执行处理，并提供超时记录提醒，超时之后就会重新发送一个同样的tuple进行处理。这个工作交给一个系统级组件acker来完成，无论是Spout还是bolt，在生成一个新的tuple之后，都会赋予其一个id，而每次tuple在被Spout发送或者被bolt处理的时候，都会向acker发送该tuple的id，而acker就能通过异或操作迅速判断出改tuple的处理情况。

在集群上，Storm提供两种节点，主节点和工作节点。

- 主节点上运行一个叫**Nimbus**的守护进程，类似于Hadoop中的JobTracker，负责向节点分派任务和故障检测。

- 工作节点运行一个叫**Supervisor**的守护进程，监听分配给它的机器，然后跟军Nimbus分配的任务来开启和结束进程。二者之间的协调关系交由Zookeeper层来实现，而Nimbus和Supervisor的进程是无状态和无法连接的，所有状态维持在Zookeeper上，以保证Storm的稳定性。

- 运行具体处理组件逻辑的进程叫**Worker**。

- worker中每一个spout/bolt的线程称为一个**task**，在0.8版本之后task不再与物理线程对应，

可以用一个展示单词频率的流来做一个简单的例子， Topology包含一个spout用来发出句子，并最终由bolt发出的每个单词在所有句子出现的次数。 每一个单词的次数更新时，一个新的计数放出。



```
//定义Topology
TopologyBuilder builder = new TopologyBuilder();

//Spout的id为1，方便其他bolt订阅这个源，从kestrel.backtype.com:22133读取数据
builder.setSpout(1, new KestrelSpout(“kestrel.backtype.com”,
                                     22133,
                                     ”sentence_queue”,
                                     new StringScheme()));
//id为2的bolt用于切割句子成为单词流的形式，使用方法SplitSentence()，然后并行量是10，然后订阅源id为1的Spout                                     
builder.setBolt(2, new SplitSentence(), 10)
        .shuffleGrouping(1);
        
builder.setBolt(3, new WordCount(), 20)
        .fieldsGrouping(2, new Fields(“word”));
```

执行切割单词：

```
publicclassSplitSentenceimplementsIBasicBolt{
    public void prepare(Map conf, TopologyContext context) {
    }
    //excute()方法是关键，利用" "将句子拆分成单词，并将每个新单词作为新元组
    public void execute(Tuple tuple, BasicOutputCollector collector) {
        String sentence = tuple.getString(0);
        for(String word: sentence.split(“ ”)) {
            collector.emit(new Values(word));
        }
    }
    public void cleanup() {
    }
    
    //宣布bolts输出元组的架构。 在这里宣布，它发出一个域为word的元组
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields(“word”));
    }
}
```
当然一个bolt也能同时订阅多个源：

```
builder.setBolt(4,newMyBolt(),12)
        .shuffleGrouping(1)
        .shuffleGrouping(2)
        .fieldsGrouping(3, new Fields(“id1″, ”id2″));
```

- - -

####关于Spark Streaming

Spark，相比于MapReduce而言，其最大的优势就在于RDD，可以快速在内存中对数据集进行迭代。对于其优点的描述，在其官网上给出的四个主要方面：1，Speed，在内存中运行性能比Hadoop好100倍，在硬盘上好10倍；2，Ease of Use，支持Java、Scala、Python和R，提供80多种高级别操作；3，Generality，集成SQL、Streaming和复杂分析，支持类库很多；4，Runs Everywhere，可以在Hadoop，Mesos，单点，云端等环境下运行。

而Spark Streaming则作为Spark核心API的扩展，专门用来处理实时流数据的可扩展、高吞吐、高容错的工具。Spark Streaming吞入的数据可以是来源于Kafka, Flume, Twitter, ZeroMQ, Kinesis, 或者TCP sockets，处理过程可以用由map, reduce, join和window组成的复杂算法，最后，处理完的结果可以推送到文件系统、数据库或者Dashboard上。

![](https://raw.githubusercontent.com/kkkelsey/kkkelsey.github.io/master/_images/streaming-arch.png)

在输入流数据到达Spark Streaming之后，将数据流分成若干个batch，然后再由Spark引擎来处理这些batch。

![](https://raw.githubusercontent.com/kkkelsey/kkkelsey.github.io/master/_images/streaming-flow.png)

由于更详细部分我已经在之前的博文[Spark streaming简介](http://kkkelsey.github.io/2014/09/Spark%20Streaming简介/)中做了简要介绍，在此不再赘述，之后会通过实际例子和Demo来解释和调试对于Spark Streaming的实际使用和开发过程。

- - -
####针对Apache Storm与Spark Streaming的比较

- **延迟性**：原则上Storm是真正的流处理，颗粒度分的更细，每次处理一条消息，所以延迟性控制的很好，实时性很高；而Spark Streaming本质上还是一种批处理的办法，但是因为批大小控制的足够微小，所以也能控制在秒级别左右。

- **容错能力**：这一点上Spark Streaming做的更好，因为其通过记录状态的办法通过RDD来实现，一旦发生错误随时都能回滚重新计算；而Storm则是通过标记和追踪消息的办法来做容错，但是一旦错误发生，某条消息可能已经被处理过许多次，与Spark中消息处理Exactly-Once相比还是逊色一筹。

- **框架实现与API**：Storm由Clojure编写，最常用支持语言是Java；而Spark Streaming是由Scala编写，支持Scala、Java、Python，其中Scala最为原生。而在资源管理上，由于Spark Streaming基于Spark，而Spark是基于Yarn，所以能领先Storm一大截。