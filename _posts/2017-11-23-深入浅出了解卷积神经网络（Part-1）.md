---

layout: post
categories: [Deep Learning]
tags: [Machine Learning, Deep Learning,  Neural Network]

---

特别鸣谢：[A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)


![](http://ope2etmx1.bkt.clouddn.com/Cover.png)

# 简介

**卷积神经网络（Convolutional neural networks）**，听起来像是一个奇怪的生物学和数学的组合，但是这些网络已经成为计算机视觉领域最有影响力的创新之一。2012年是神经网络成长的第一年，Alex Krizhevsky用它们赢得了当年的ImageNet竞赛（基本上是计算机视觉年度奥运会），把分类错误记录从26％降低到了15％，这是一个惊人的提高。从那以后，许多公司一直在以深度学习作为他们的服务核心。Facebook使用神经网络作为自动标记算法，谷歌用作照片搜索，亚马逊用作产品推荐，Pinterest用作主页需求个性化，Instagram则用作搜索基础设施。

![](http://ope2etmx1.bkt.clouddn.com/Companies.png)

然而，这些网络最经典最流行的用例是用于图像处理。在图像处理中过程中，让我们来看看如何使用这些CNN进行图像分类。

- - -

# 问题空间

图像分类是通过输入图像来输出类别（猫，狗等）或能描述图像类别的最大概率的任务。对于人类来说，我们必须承认，这项任务是我们从出生那一刻起学到的第一个技能之一，并且是成年人自然而然毫不费力的技能。即使不假思索，我们也能够快速无缝地识别我们所处的环境以及周围的物体。当我们看到一张图像或者只是看着周围的世界时，部分时间我们都能够立刻刻画这个场景，给每个对象一个标签，甚至所有这些都没有自觉地注意到。这些能够快速识别模式，从先前的知识进行概括并适应不同的图像环境的技能却是我们不能与我们的机器同伴共享的技能。

- - -

# 输入和输出

当一台电脑看到一个图像（以图像作为输入）时，它会看到的是一个由像素值组成的数组。根据图像的分辨率和大小，它可能看到的是一个`32×32×3`的数字数组（3指的是RGB值）。为了说明这一点，假设我们有一个JPG格式的彩色图像，它的大小是`480x`480`，那么代表它的数组将是`480x480x3`。这些数字中的每一个都是一个0到255之间的值，它描述的是该点的像素强度。这些数字对于我们人类自身进行图像分类时毫无意义，但这却是计算机唯一可用的输入。这个概念就是，你给计算机这串数字组成的数组，它会输出一个结果数字，描述了图像是某一个类的概率（比如0.80的可能性为猫，0.15为狗，0.05为鸟等）。

![](http://ope2etmx1.bkt.clouddn.com/Corgi3.png)


- - -

# 我们希望计算机做什么

既然我们知道这个问题以及输入和输出了，我们来思考如何解决这个问题。我们希望计算机做的是能够区分所有的图像，并找出使狗成为狗或使猫成为猫的独特功能。这也是下意识地在我们的脑海中继续的过程。当我们看一张狗的照片时，如果照片具有可识别的特征，例如爪子或四条腿，我们可以将其分类。以类似的方式，计算机能够通过查找诸如边缘和曲线等低级特征来执行图像分类，然后通过一系列卷积层来构建更抽象的概念。这是一个CNN的一般概述。 我们来详细说明一下。

- - -

# 生物学上的联系

但首先，有一点背景知识需要介绍，当你第一次听说卷积神经网络这个术语的时候，你可能已经想到了一些与神经科学或生物学有关的东西。是的，CNNs最初确实从视觉皮层中获得生物启发。视觉皮层是具有对视野特定区域敏感的细胞区域。这个想法在Hubel和Wiesel于1962年进行的一个迷人的实验中得到了扩展（[视频](https://www.youtube.com/watch?v=Cw5PKV9Rj3o)），他们发现大脑中的某些单个神经元细胞只有在一定方向的边缘存在的情况下才会响应（或发射）。例如，一些神经元在暴露于垂直边缘时响应，而另一些在显示水平或对角边缘时响应。 Hubel和Wiesel发现，所有这些神经元都是以柱状结构组织的，并且能够产生视觉感受，在具有特定任务的系统内的特定组件（在视觉皮层中寻找特定特征的神经元细胞）的这种想法也是机器适用的，并且是CNN背后的基础。

- - -

# 结构

回到具体细节上，有关对CNN做的更详细的概述是：你将图像传递给一系列非线性的卷积，经过池化（向下采样）和全连接的层，并获得输出。正如我们前面所说的那样，输出可以是一个类或一个最能描述图像的类的概率。现在，困难的部分是了解每个层次都做了什么。所以先让我们进入最重要的一个层。

- - -

# 第一层-数学部分

CNN中的第一层始终是一个**卷积层（Convolutional Layer）**。首先你要确保记得这个conv（我将使用这个缩写很多）的输入是什么。就像我们之前提到的那样，输入是一个`32×32×3`的像素值数组。现在，解释一个conv层的最好方法就是想象一个闪烁在图像左上角的手电筒。假设这个手电筒照射的光线覆盖了`5×5`的区域。现在，让我们想象这个手电筒滑过输入图像的所有区域。在机器学习方面，这种手电筒被称为**过滤器filter**（有时也称为**神经元neuron**或**内核kernel**），它所照射的区域称为**接收域receptive field**。现在，这个过滤器也是一个由数字组成的数组（这些数字称为**权重weight**或**参数parameters**）。一个非常重要的注意事项是，这个过滤器的深度必须和输入的深度相同（这可以确保数学运算顺利进行），所以这个过滤器的尺寸是`5x5x3`。现在，我们来以过滤器的第一个位置举例子：这将是输入图像的左上角，当过滤器在输入图像周围滑动或**卷积convolving**时，它将过滤器中的值与图像的原始像素值相乘（也称为**计算元素智能乘法element-wise multiplications**）。所有这些乘法都被求出来并计算总和（从数学上讲，这将是总共75次乘法）。所以，现在你将会获得一个单一的数字。记住，这个数字只是过滤器位于图像左上角的代表。现在，我们对输入体量上的每个位置重复这个过程。（下一步将过滤器向右移动1个单位，然后再向右移动1，依此类推）。输入体量上的每个唯一位置都会生成一个数字。在所有位置上滑动过滤器后，你将发现剩下的是一个`28x28x1`的数字数组，我们称之为**激活图activation map**或**特征图feature map**。之所以会是一个`28×28`阵列的原因是因为一个`5×5`的滤波器可以放在一个`32×32`输入图像上的784个不同的位置。这784个数字被映射到一个`28×28`数组。

![](http://ope2etmx1.bkt.clouddn.com/ActivationMap.png)

(Quick Note: Some of the images, including the one above, I used came from this terrific book, ["Neural Networks and Deep Learning"](http://neuralnetworksanddeeplearning.com/) by Michael Nielsen. Strongly recommend.)

假设我们现在使用两个`5x5x3`过滤器，那么我们的输出量将是`28x28x2`，通过使用更多的过滤器，我们能够更好地保留空间尺寸。在数学上，这是卷积层中发生的事情。

- - -

# 第一层-高层透视图

现在，让我们从更高层次上来谈论这个卷积实际上在做什么。这里每个过滤器都可以被认为是一个**特征标识器feature identifiers**。当我提到特征时，事实上指的就是直线边缘、简单的颜色和曲线等。试想所有图像最简单的共同点。假设我们的第一个过滤器是`7x7x3`并且将成为曲线检测器。（在本节中，为了简单起见，让我们忽略过滤器深度为3单位的事实，并且只考虑过滤器和图像的顶部深度切片）。作为曲线检测器，过滤器将具有像素结构，沿曲线形状的区域是更高的数值（请记住，我们正在讨论的这些滤波器只是数字！）。

![](http://ope2etmx1.bkt.clouddn.com/Filter.png)

现在，让我们回到将这个数学问题可视化上。当我们在输入体量的左上角有这样一个滤波器时，它将计算该区域的过滤器和像素值之间的乘积。现在让我们举一个需要进行分类的图像的例子，让我们先把过滤器定位在左上角。

![](http://ope2etmx1.bkt.clouddn.com/OriginalAndFilter.png)

记住，我们要做的事情就是将过滤器中的数字和图像上的原始像素点的数值做乘积。

![](http://ope2etmx1.bkt.clouddn.com/FirstPixelMulitiplication.png)

通常情况下，在输入图像上，如果有一个类似于这个过滤器所代表的曲线的形状，那么所覆盖的像素点和过滤器上的点的乘积相加在一起将会产生一个大的值！现在让我们看看当我们移动过滤器时会发生什么。

![](http://ope2etmx1.bkt.clouddn.com/SecondMultiplication.png)

这个值降低了很多！这是因为图像部分中没有任何东西响应曲线检测器过滤器。记住，这个conv层的输出是一个激活图。所以在只有一个单一过滤器卷积的简单情况下（如果该过滤器是曲线检测器），激活图将显示图片中最有可能是曲线的区域。在这个例子中，我们的`26x26x1`激活图的左上角（26是因为`7x7`滤镜而不是`5x5`）将是6600。这个高值意味着在输入中可能有某种曲线导致过滤器产生较高的激活量。在我们的激活图中，右上角的值将是0，因为在输入体量中没有任何东西导致过滤器激活（或者更简单地说，在原始图像的该区域中没有相应的曲线）。请记住，这只是一个过滤器，这只是一个能检测到向右和向外弯曲的线条的过滤器。我们还可以使用其他的检测向左曲线或直线的过滤器。如果用了更多的过滤器，那么激活图的深度越大，我们对输入量的了解也越多。

声明：本节中描述的过滤器只是对卷积过程中数学的主要目的简单化描述。 在下面的图片中，将看到一些经过训练的网络的第一个conv层过滤器的实际可视化示例。 尽管如此，主要论点仍然是一样的。第一层上的过滤器在输入图像周围进行卷积，并在其正在查找的特定功能在输入体量中被检测到时“激活”（或计算高值）。

![](http://ope2etmx1.bkt.clouddn.com/FirstLayers.png)

(Quick Note: The above image came from Stanford's [CS231N](http://cs231n.stanford.edu/) course taught by Andrej Karpathy and Justin Johnson. Recommend for anyone looking for a deeper understanding of CNNs.)

- - -

# 深入到网络中

现在在传统的卷积神经网络架构中，在这些conv层之间还有其他层。我强烈推荐有兴趣的读者去了解他们的功能和效果，从一般意义上说，他们为模型提供了非线性特性和保持了维度，有助于提高网络的鲁棒性和控制过拟合。一个经典的CNN架构看起来就像这样。

![](http://ope2etmx1.bkt.clouddn.com/Table.png)

然而，最后一层是一个重要的层，我们稍后会介绍。让我们退一步看看迄今为止我们已经学到了什么。我们讨论了第一个conv层中的过滤器是用来检测的。他们检测低级功能，如边缘和曲线。正如人们所想象的，为了预测图像是否是一种对象，我们需要网络能够识别更高层次的特征，如手或爪子或耳朵。那么让我们来思考第一个conv层之后的网络输出结果。这将是一个`28×28×3`的体量（假设我们使用三个`5×5×3`滤波器）。当我们经过另一个conv层时，第一个conv层的输出成为第二个conv层的输入。现在，这看起来有点难以想象。当我们在谈论第一层时，输入只是原始图像。但是，当我们谈论第二个conv层时，输入是第一层产生的激活图。因此，输入的每一层都基本上描述了原始图像中某些低级特征出现的位置。现在，当你在上面应用一组过滤器（通过第二个conv层传递它）时，输出将是代表更高级别特征的激活值。这些特征的类型可以是半圆（曲线和直边的组合）或正方形（几个直边的组合）。当你经过整个网络并通过更多的conv层时，将获得代表越来越复杂功能的激活映射图。在网络最末端，你可能会通过一些过滤器获得在图像中有手写时激活，在看到粉红色的物体时激活，等等。如果你想要了解关于在ConvNets中可视化过滤器的更多信息，Matt Zeiler和Rob Fergus有一个很好的[研究论文](http://www.matthewzeiler.com/pubs/arxive2013/arxive2013.pdf)来讨论这个话题。 Jason Yosinski在YouTube上也有一个[视频](https://www.youtube.com/watch?v=AgkfIQ4IGaM)，提供了一个很棒的视觉表现。另一个值得注意的事情是，当你深入到网络中时，过滤器开始具有越来越大的接受范围，这意味着他们能够从原始输入量的较大区域考虑信息（另一种支持这个观点的依据是它们对越来越大的像素空间区域越来越敏感）。

- - -

# 全连接层

既然我们可以检测到这些高级功能，那么锦上添花的就是将一个完全连接的层连接到网络的末端。原则上，这个层需要一个输入量（无论是在其之前的conv或ReLU还是pool层输出），并输出一个N维向量，其中N是程序必须从中选择的类的数量。例如，如果你想要一个数字分类程序，N将是10，因为有10个数字。这个N维向量中的每个数字表示某个类别的概率。例如，如果用于数字分类程序的结果向量是`[0.1, 0.1, 0.75, 0, 0, 0, 0, 0, 0.05, 0]`，那么这代表有10％的概率图像是1，10％的概率图像是2，图像是3的概率是75％，图像是9的概率是5％（注意：还有其他方法可以表示输出，但我只是展示了softmax方法）。这个全连接层的工作方式是查看上一层的输出（我们记得它应该代表高级特征的激活图），并确定哪些特征与特定类最相关。例如，如果程序预测某些图像是狗，则在激活图中将具有高值，例如爪子或四条腿等的高级特征。类似地，如果程序预测某图像是鸟，那么代表像翅膀或喙等高级特征将在激活图中具有很高的值。基本上，全连接层会考虑什么高层特征与特定类最强关联，并具有特定的权重，以便只要你计算权重和前一层之间的乘积，就可以得到不同类别的正确概率。

![](http://ope2etmx1.bkt.clouddn.com/LeNet.png)

- - -

# 训练（如何让这一切运作起来）

这是我故意没有提到的神经网络的一个方面，但它可能是最重要的部分。在阅读时可能有很多疑问：第一个conv层中的过滤器如何知道要去查找边和曲线？全连接层如何知道要查看什么样的激活图？每层中的过滤器如何知道应该被设置成什么值？计算机能够调整其过滤值（或权重）的方式是通过称为**反向传播（backpropagation）**的训练过程。

在我们进入反向传播之前，我们必须先退后一步来讨论神经网络的工作需求。在我们出生的那一刻，我们的思想是全新的，我们不知道什么是猫、狗或鸟。同样，在CNN开始之前，权重或过滤值都是随机的，过滤器不知道去寻找边缘和曲线，在更高层的过滤器不知道去寻找爪子和喙。然而，随着年龄的增长，我们的父母和老师向我们展示了不同的图片和照片，并给了我们相应的标签。被赋予图像和标签的想法同样也是CNN经历的训练过程所需要经历的。在深入研究之前，我们假设我们有一套训练集，里面有成千上万的狗、猫和鸟的图像，而且每张图片都有一个这个图片是什么动物的标签。然后在让我们回到回到反向传播的话题上来。

所以反向传播可以分为4个不同的部分：

- 正向传递
- 损失函数
- 反向传递
- 权重更新

在**正向传递forward pass**过程中，首先将选择一张训练图像，我们记得这是一个`32x32x3`的数字数组，并将其传递给整个网络。在我们的第一个训练样例中，由于所有的权值和过滤值都是随机初始化的，因此输出结果可能类似`[.1 .1 .1 .1 .1 .1 .1 .1 .1]`，基本上输出都没有特定的数字。在当前的权重下，网络无法查找到这些低级特征，因此无法就分类的可能性得出任何合理的结论。这就转到了反向传播的**损失函数Loss Function**部分。请记住，我们现在使用的是训练数据，这个数据有一个图像和一个标签。例如，假设输入的第一个训练图像是3，图像的标签是`[0 0 0 1 0 0 0 0 0 0]`。损失函数可以用许多不同的方式来定义，但常见的是MSE（均方误差），即（实际值-预测值）的平方的1/2倍。

![](http://ope2etmx1.bkt.clouddn.com/Equation.png)

假设变量L等于该值。正如你可以想象的那样，第一对训练图像的损失值将非常高。 现在，让我们直观地思考这个问题。我们希望达到预测的标签（ConvNet的输出）与训练标签相同的点（这意味着我们的网络做出了正确的预测）。为了达到这个目的，我们希望最小化我们得到的损失值。可以将这看作是微积分中的一个优化问题，我们想要找出哪些输入（在我们的例子中是权重）最直接地造成了网络的损失（或错误）。

![](http://ope2etmx1.bkt.clouddn.com/Loss.png)

这是**dL/dW**的数学等式，其中W是特定层的权重。现在，我们要做的是通过网络进行反向传递，即确定哪些权重对损失贡献最大，并设法调整这些权重，从而减少损失。一旦我们计算出这个导数，我们就会进入最后一步——权重更新**weight update**。这就是我们如何获得所有过滤器的权重，并更新它们，使它们向梯度的相反方向变化。

![](http://ope2etmx1.bkt.clouddn.com/Weight.png)

**学习率Learning rate**是由程序员选择的参数。高学习率意味着在权重更新中采取更大的步幅，因此，模型可能花费更少的时间来收敛到最优权重集。但是，如果学习率过高，可能会导致跳跃过大，不够精确，无法达到最佳点。

![](http://ope2etmx1.bkt.clouddn.com/HighLR.png)

正向传递，损失函数，反向传递和参数更新的过程是一次训练迭代。程序将不断重复这个过程，对每组训练图像（通常称为**批次batch**）进行固定次数的迭代。 一旦你完成了最后一个训练样例的参数更新，希望你的网络已经被训练得足够好，这样才能让各个层的权重被正确地调整。

- - -

# 测试

最后，为了看看我们的CNN是否有效，我们有一套不同的图像和标签集合（在训练和测试之间不能一蹴而就），并将这个测试结合通过CNN。我们将输出与实际情况进行比较，看看我们的网络是否正常工作！

- - -

# 大公司如何使用CNN

数据，数据，数据。那些拥有数据的公司就是那些比其他竞争者更具有内在优势的公司。你可以为网络提供的训练数据越多，你就可以进行越多的训练迭代次数，就可以进行越多的权重更新，那么在投入生产之后网络的调整就越好。Facebook（和Instagram）可以使用目前拥有的十亿用户的所有照片，Pinterest可以使用其网站上500亿个pins的信息，Google可以使用搜索数据，而Amazon可以使用每天被购买的数百万种产品。现在你知道他们如何使用它的魔法了。

- - -

# 声明

尽管这篇文章应该是理解CNN的好开始，但这并不是一个全面的概述。在这篇文章中没有讨论的东西包括非线性和合并层以及网络的超参数，如过滤器大小，步长和填充。 还没有讨论网络架构，批量归一化，梯度减小，dropout，初始化技术，非凸优化，偏差，损失函数选择，数据增强，正则化方法，计算考虑，反向传播修改等主题。

[Links to Part2](http://kakack.github.io/2017/11/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E4%BA%86%E8%A7%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Part-2/)
