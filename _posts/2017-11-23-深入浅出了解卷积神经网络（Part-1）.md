---

layout: post
categories: [Deep Learning]
tags: [Machine Learning, Deep Learning,  Neural Network]

---

特别鸣谢：[A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)


![](http://ope2etmx1.bkt.clouddn.com/Cover.png)

# 简介

**卷积神经网络（Convolutional neural networks）**，听起来像是一个奇怪的生物学和数学的组合，但是这些网络已经成为计算机视觉领域最有影响力的创新之一。2012年是神经网络成长的第一年，Alex Krizhevsky用它们赢得了当年的ImageNet竞赛（基本上是计算机视觉年度奥运会），把分类错误记录从26％降低到了15％，这是一个惊人的提高。从那以后，许多公司一直在以深度学习作为他们的服务核心。Facebook使用神经网络作为自动标记算法，谷歌用作照片搜索，亚马逊用作产品推荐，Pinterest用作主页需求个性化，Instagram则用作搜索基础设施。

![](http://ope2etmx1.bkt.clouddn.com/Companies.png)

然而，这些网络最经典最流行的用例是用于图像处理。在图像处理中过程中，让我们来看看如何使用这些CNN进行图像分类。

- - -

# 问题空间

图像分类是通过输入图像来输出类别（猫，狗等）或能描述图像类别的最大概率的任务。对于人类来说，我们必须承认，这项任务是我们从出生那一刻起学到的第一个技能之一，并且是成年人自然而然毫不费力的技能。即使不假思索，我们也能够快速无缝地识别我们所处的环境以及周围的物体。当我们看到一张图像或者只是看着周围的世界时，部分时间我们都能够立刻刻画这个场景，给每个对象一个标签，甚至所有这些都没有自觉地注意到。这些能够快速识别模式，从先前的知识进行概括并适应不同的图像环境的技能却是我们不能与我们的机器同伴共享的技能。

- - -

# 输入和输出

当一台电脑看到一个图像（以图像作为输入）时，它会看到的是一个由像素值组成的数组。根据图像的分辨率和大小，它可能看到的是一个`32×32×3`的数字数组（3指的是RGB值）。为了说明这一点，假设我们有一个JPG格式的彩色图像，它的大小是`480x`480`，那么代表它的数组将是`480x480x3`。这些数字中的每一个都是一个0到255之间的值，它描述的是该点的像素强度。这些数字对于我们人类自身进行图像分类时毫无意义，但这却是计算机唯一可用的输入。这个概念就是，你给计算机这串数字组成的数组，它会输出一个结果数字，描述了图像是某一个类的概率（比如0.80的可能性为猫，0.15为狗，0.05为鸟等）。

![](http://ope2etmx1.bkt.clouddn.com/Corgi3.png)


- - -

# 我们希望计算机做什么

既然我们知道这个问题以及输入和输出了，我们来思考如何解决这个问题。我们希望计算机做的是能够区分所有的图像，并找出使狗成为狗或使猫成为猫的独特功能。这也是下意识地在我们的脑海中继续的过程。当我们看一张狗的照片时，如果照片具有可识别的特征，例如爪子或四条腿，我们可以将其分类。以类似的方式，计算机能够通过查找诸如边缘和曲线等低级特征来执行图像分类，然后通过一系列卷积层来构建更抽象的概念。这是一个CNN的一般概述。 我们来详细说明一下。

- - -

# 生物学上的联系

但首先，有一点背景知识需要介绍，当你第一次听说卷积神经网络这个术语的时候，你可能已经想到了一些与神经科学或生物学有关的东西。是的，CNNs最初确实从视觉皮层中获得生物启发。视觉皮层是具有对视野特定区域敏感的细胞区域。这个想法在Hubel和Wiesel于1962年进行的一个迷人的实验中得到了扩展（[视频](https://www.youtube.com/watch?v=Cw5PKV9Rj3o)），他们发现大脑中的某些单个神经元细胞只有在一定方向的边缘存在的情况下才会响应（或发射）。例如，一些神经元在暴露于垂直边缘时响应，而另一些在显示水平或对角边缘时响应。 Hubel和Wiesel发现，所有这些神经元都是以柱状结构组织的，并且能够产生视觉感受，在具有特定任务的系统内的特定组件（在视觉皮层中寻找特定特征的神经元细胞）的这种想法也是机器适用的，并且是CNN背后的基础。

- - -

# 结构

回到具体细节上，有关对CNN做的更详细的概述是：你将图像传递给一系列非线性的卷积，经过池化（向下采样）和全连接的层，并获得输出。正如我们前面所说的那样，输出可以是一个类或一个最能描述图像的类的概率。现在，困难的部分是了解每个层次都做了什么。所以先让我们进入最重要的一个层。

- - -

# 第一层-数学部分

CNN中的第一层始终是一个**卷积层（Convolutional Layer）**。首先你要确保记得这个conv（我将使用这个缩写很多）的输入是什么。就像我们之前提到的那样，输入是一个`32×32×3`的像素值数组。现在，解释一个conv层的最好方法就是想象一个闪烁在图像左上角的手电筒。假设这个手电筒照射的光线覆盖了`5×5`的区域。现在，让我们想象这个手电筒滑过输入图像的所有区域。在机器学习方面，这种手电筒被称为**过滤器filter**（有时也称为**神经元neuron**或**内核kernel**），它所照射的区域称为**接收域receptive field**。现在，这个过滤器也是一个由数字组成的数组（这些数字称为**权重weight**或**参数parameters**）。一个非常重要的注意事项是，这个过滤器的深度必须和输入的深度相同（这可以确保数学运算顺利进行），所以这个过滤器的尺寸是`5x5x3`。现在，我们来以过滤器的第一个位置举例子：这将是输入图像的左上角，当过滤器在输入图像周围滑动或**卷积convolving**时，它将过滤器中的值与图像的原始像素值相乘（也称为**计算元素智能乘法element-wise multiplications**）。所有这些乘法都被求出来并计算总和（从数学上讲，这将是总共75次乘法）。所以，现在你将会获得一个单一的数字。记住，这个数字只是过滤器位于图像左上角的代表。现在，我们对输入体量上的每个位置重复这个过程。（下一步将过滤器向右移动1个单位，然后再向右移动1，依此类推）。输入体量上的每个唯一位置都会生成一个数字。在所有位置上滑动过滤器后，你将发现剩下的是一个`28x28x1`的数字数组，我们称之为**激活图activation map**或**特征图feature map**。之所以会是一个`28×28`阵列的原因是因为一个`5×5`的滤波器可以放在一个`32×32`输入图像上的784个不同的位置。这784个数字被映射到一个`28×28`数组。

![](http://ope2etmx1.bkt.clouddn.com/ActivationMap.png)

(Quick Note: Some of the images, including the one above, I used came from this terrific book, ["Neural Networks and Deep Learning"](http://neuralnetworksanddeeplearning.com/) by Michael Nielsen. Strongly recommend.)

假设我们现在使用两个`5x5x3`过滤器，那么我们的输出量将是`28x28x2`，通过使用更多的过滤器，我们能够更好地保留空间尺寸。在数学上，这是卷积层中发生的事情。

- - -

# 第一层-高层透视图

现在，让我们从更高层次上来谈论这个卷积实际上在做什么。这里每个过滤器都可以被认为是一个**特征标识器feature identifiers**。当我提到特征时，事实上指的就是直线边缘、简单的颜色和曲线等。试想所有图像最简单的共同点。假设我们的第一个过滤器是`7x7x3`并且将成为曲线检测器。（在本节中，为了简单起见，让我们忽略过滤器深度为3单位的事实，并且只考虑过滤器和图像的顶部深度切片）。作为曲线检测器，过滤器将具有像素结构，沿曲线形状的区域是更高的数值（请记住，我们正在讨论的这些滤波器只是数字！）。

![](http://ope2etmx1.bkt.clouddn.com/Filter.png)

现在，让我们回到将这个数学问题可视化上。当我们在输入体量的左上角有这样一个滤波器时，它将计算该区域的过滤器和像素值之间的乘积。现在让我们举一个需要进行分类的图像的例子，让我们先把过滤器定位在左上角。

![](http://ope2etmx1.bkt.clouddn.com/OriginalAndFilter.png)

记住，我们要做的事情就是将过滤器中的数字和图像上的原始像素点的数值做乘积。

![](http://ope2etmx1.bkt.clouddn.com/FirstPixelMulitiplication.png)

通常情况下，在输入图像上，如果有一个类似于这个过滤器所代表的曲线的形状，那么所覆盖的像素点和过滤器上的点的乘积相加在一起将会产生一个大的值！现在让我们看看当我们移动过滤器时会发生什么。

![](http://ope2etmx1.bkt.clouddn.com/SecondMultiplication.png)

这个值降低了很多！这是因为图像部分中没有任何东西响应曲线检测器过滤器。记住，这个conv层的输出是一个激活图。所以在只有一个单一过滤器卷积的简单情况下（如果该过滤器是曲线检测器），激活图将显示图片中最有可能是曲线的区域。在这个例子中，我们的`26x26x1`激活图的左上角（26是因为`7x7`滤镜而不是`5x5`）将是6600。这个高值意味着在输入中可能有某种曲线导致过滤器产生较高的激活量。在我们的激活图中，右上角的值将是0，因为在输入体量中没有任何东西导致过滤器激活（或者更简单地说，在原始图像的该区域中没有相应的曲线）。请记住，这只是一个过滤器，这只是一个能检测到向右和向外弯曲的线条的过滤器。我们还可以使用其他的检测向左曲线或直线的过滤器。如果用了更多的过滤器，那么激活图的深度越大，我们对输入量的了解也越多。

声明：本节中描述的过滤器只是对卷积过程中数学的主要目的简单化描述。 在下面的图片中，将看到一些经过训练的网络的第一个conv层过滤器的实际可视化示例。 尽管如此，主要论点仍然是一样的。第一层上的过滤器在输入图像周围进行卷积，并在其正在查找的特定功能在输入体量中被检测到时“激活”（或计算高值）。

![](http://ope2etmx1.bkt.clouddn.com/FirstLayers.png)

(Quick Note: The above image came from Stanford's [CS231N](http://cs231n.stanford.edu/) course taught by Andrej Karpathy and Justin Johnson. Recommend for anyone looking for a deeper understanding of CNNs.)

- - -

# 深入到网络中

现在在传统的卷积神经网络架构中，在这些conv层之间还有其他层。我强烈推荐有兴趣的读者去了解他们的功能和效果，从一般意义上说，他们为模型提供了非线性特性和保持了维度，有助于提高网络的鲁棒性和控制过拟合。一个经典的CNN架构看起来就像这样。

![](http://ope2etmx1.bkt.clouddn.com/Table.png)

然而，最后一层是一个重要的层，我们稍后会介绍。让我们退一步看看迄今为止我们已经学到了什么。我们讨论了第一个conv层中的过滤器是用来检测的。他们检测低级功能，如边缘和曲线。正如人们所想象的，为了预测图像是否是一种对象，我们需要网络能够识别更高层次的特征，如手或爪子或耳朵。那么让我们来思考第一个conv层之后的网络输出结果。这将是一个`28×28×3`的体量（假设我们使用三个`5×5×3`滤波器）。当我们经过另一个conv层时，第一个conv层的输出成为第二个conv层的输入。现在，这看起来有点难以想象。当我们在谈论第一层时，输入只是原始图像。但是，当我们谈论第二个conv层时，输入是第一层产生的激活图。因此，输入的每一层都基本上描述了原始图像中某些低级特征出现的位置。现在，当你在上面应用一组过滤器（通过第二个conv层传递它）时，输出将是代表更高级别特征的激活值。这些特征的类型可以是半圆（曲线和直边的组合）或正方形（几个直边的组合）。当你经过整个网络并通过更多的conv层时，将获得代表越来越复杂功能的激活映射图。在网络最末端，你可能会通过一些过滤器获得在图像中有手写时激活，在看到粉红色的物体时激活，等等。如果你想要了解关于在ConvNets中可视化过滤器的更多信息，Matt Zeiler和Rob Fergus有一个很好的[研究论文](http://www.matthewzeiler.com/pubs/arxive2013/arxive2013.pdf)来讨论这个话题。 Jason Yosinski在YouTube上也有一个[视频](https://www.youtube.com/watch?v=AgkfIQ4IGaM)，提供了一个很棒的视觉表现。另一个值得注意的事情是，当你深入到网络中时，过滤器开始具有越来越大的接受范围，这意味着他们能够从原始输入量的较大区域考虑信息（另一种支持这个观点的依据是它们对越来越大的像素空间区域越来越敏感）。

- - -

# 全连接层

![](http://ope2etmx1.bkt.clouddn.com/LeNet.png)

- - -

# 训练（如何让这一切运作起来）

![](http://ope2etmx1.bkt.clouddn.com/Equation.png)

![](http://ope2etmx1.bkt.clouddn.com/Loss.png)

![](http://ope2etmx1.bkt.clouddn.com/Weight.png)

![](http://ope2etmx1.bkt.clouddn.com/HighLR.png)

- - -

# 测试

- - -

# 大公司如何使用CNN

- - -

# 声明

[Links to Part2](http://kakack.github.io/2017/11/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E4%BA%86%E8%A7%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Part-2/)
