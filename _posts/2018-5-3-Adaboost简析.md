---

layout: post
categories: [Machine Learning]
tags: [Machine Learning, AdaBoost]

---

`AdaBoost`的主要用途是将若干个‘弱分类器（weak classifier）’结合起来行程一个‘强分类器（strong classifier）’，主要用于二元分类上。其中，弱分类器的意思是性能较差的分类器，大概只比随机分类好一丢丢，比如简单地根据一个人的身高来判断性别，假定判别依据是172以上是男性，以下是女性，那最后的正确率应该也仅仅是过50%。

AdaBoost可以应用在所有类型的分类算法上，因此它是建立于其他所有优秀的分类算法上，而它自身并不能算作一种分类算法。

AdaBoost真正做的是两件事情：

一，为你将要训练的分类器提供合适的训练数据集，这个训练集的选择是根据上一个分类器的结果而定。

二，在得到联合的分类结果时，为这个结果中各个分类器得到的结果选定合适的权重

- - -

# 数据集选择

对于要被结合的每一个弱分类器而言，都必须在总训练集的一个随机的子集上进行训练，这些自己是可以互相重叠的，并非是被划分成等大小的若干个分片。AdaBoost给每个训练样本都分配一个`权重weight`，这个权重决定了每一个样本可能在训练集中出现的概率，越高权重的样本越可能被选进到训练集中。当训练结束之后，AdaBoost将会提高那些被错分类的样本的权重，使得它们之后在分类器训练过程中发挥更大的作用，希望之后的分类器能在这些样本上能有更好的表现。具体的公式会在之后定义。

- - -

# 分类器输出权重

当每一个分类器都训练完毕，这些分类器各自的结果的权重会根据它们的正确率来计算，越精确的分类器会得到越高的权重。一个正确率50%的分类器会得到权重`0`，认为其对正确分类没什么作用；而正确率低于50%的分类器则会被赋予负值作为权重，认为其对正确分类具有反面作用。

- - -

# 正式定义

AdaBoost的最终结果是`T`个弱分类器结果的线性组合取正负号，其中`ht(x)`是`弱分类器t`的输出结果（在论文中姑且认为位于区间`(-1, 1)`），`αt`是`弱分类器t`的权重（由AdaBoost计算得到）。

![](http://ope2etmx1.bkt.clouddn.com/adaboost_finalclassifier.png)

每个弱分类器是一次训练一个，当一个弱训练器训练完毕，我们会根据其结果来更新下一个弱分类器训练所需的训练集中，各个训练样本可能出现的概率。

其中第一个弱分类器所训练的训练集中，各个训练样本出现概率是相等的，在这之后我们更新得到这个训练集结果在最终结果中所占的权重值：

![](http://ope2etmx1.bkt.clouddn.com/classifieralpha.png)

`αt`是各个输出值的权重，基于分类器的错误率`εt`，`εt`是训练集`Dt`中，分类结果与样本标签不等的概率。

下图是`αt`和错误率`εt`之间的关系：

![](http://ope2etmx1.bkt.clouddn.com/adaboost_alphacurve.png)

1. 当错误率为0时，权重值急速增长，表示越好的分类器会被赋予越大的权重值。
2. 当错误率为50%时，会被赋予权重0，也就是不需要几乎随机猜测的分类器。
3. 当错误率接近1时，权重值急速减少变成负值。

当权重值计算结束后，我们依据下图公式更新训练样本的权重值：

![](http://ope2etmx1.bkt.clouddn.com/adaboost_distributionupdate.png)

其中`Dt`是表示权重的向量，每一个训练样本都有一个权重。其中`i`是当前样本序号。在论文中，`Dt`被描述成一种分布，其中的`D(i)`表示了编号为`i`的训练样本会被下一个训练集选中的概率。

为了使得`Dt`成为一种分布形式，其中所有的概率之和需要等于恒值——`1`。为了确保这一点，我们在权重上进行正则化，将每一个权重除以所有权重的和。

![](http://ope2etmx1.bkt.clouddn.com/exp_x.png)


