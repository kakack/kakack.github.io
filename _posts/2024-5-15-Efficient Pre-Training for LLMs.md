---

layout: post
tags: [LLM, NLP, Pre-Training]
title: Efficient Pre-Training for LLMs
date: 2024-05-15
author: Kaka Chen
comments: true
toc: true
pinned: false

---

# Intro

# Mixed Precision Acceleration

# Scaling Models

# Initialization Techniques

# Optimization Strategies

# System-Level Pre-Training Efficiency Optimization

# Conclusion