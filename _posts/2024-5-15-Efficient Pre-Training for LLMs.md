---

layout: post
tags: [LLM, NLP, Pre-Training]
title: Efficient Pre-Training for LLMs
date: 2024-05-15
author: Kaka Chen
comments: true
toc: true
pinned: false

---

# 1 - Intro

# 2 - Mixed Precision Acceleration

# 3 - Scaling Models

# 4 - Initialization Techniques

# 5 - Optimization Strategies

# 6 - System-Level Pre-Training Efficiency Optimization

# 7 - Conclusion