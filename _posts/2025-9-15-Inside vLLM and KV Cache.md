---

layout: post
tags: [LLM, NLP, AI Infra]
title: Inside vLLM and KV Cache
date: 2025-9-15
author: Kyrie Chen
comments: true
toc: true
pinned: false

---

éšç€å¤§è¯­è¨€æ¨¡å‹(LLM)åœ¨å„ä¸ªé¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼Œå¦‚ä½•é«˜æ•ˆåœ°éƒ¨ç½²å’Œæ¨ç†è¿™äº›æ¨¡å‹æˆä¸ºäº†ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„æ¨¡å‹æ¨ç†æœåŠ¡å¾€å¾€é¢ä¸´ç€å†…å­˜åˆ©ç”¨ç‡ä½ã€ååé‡å—é™ã€å»¶è¿Ÿä¸å¯æ§ç­‰é—®é¢˜ï¼Œè¿™äº›ç“¶é¢ˆä¸¥é‡åˆ¶çº¦äº†LLMåœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„è§„æ¨¡åŒ–åº”ç”¨ã€‚vLLMä½œä¸ºä¸€ä¸ªä¸“ä¸ºLLMä¼˜åŒ–çš„é«˜æ€§èƒ½æ¨ç†æœåŠ¡æ¡†æ¶ï¼Œé€šè¿‡ä¸€ç³»åˆ—åˆ›æ–°çš„æŠ€æœ¯æ–¹æ¡ˆï¼Œæœ‰æ•ˆè§£å†³äº†è¿™äº›ç—›ç‚¹é—®é¢˜ã€‚

æœ¬æ–‡å°†æ·±å…¥å‰–ævLLMçš„æ ¸å¿ƒæ¶æ„å’Œå…³é”®æŠ€æœ¯å®ç°ï¼Œä»åº•å±‚çš„å†…å­˜ç®¡ç†æœºåˆ¶åˆ°ä¸Šå±‚çš„æœåŠ¡è°ƒåº¦ç­–ç•¥ï¼Œå…¨é¢è§£æå…¶å¦‚ä½•å®ç°é«˜æ•ˆçš„LLMæ¨ç†æœåŠ¡ã€‚æˆ‘ä»¬å°†é‡ç‚¹æ¢è®¨ä»¥ä¸‹å‡ ä¸ªæ ¸å¿ƒæŠ€æœ¯æ¨¡å—ï¼š

**PagedAttentionæœºåˆ¶**ï¼šå€Ÿé‰´æ“ä½œç³»ç»Ÿä¸­è™šæ‹Ÿå†…å­˜ç®¡ç†çš„æ€æƒ³ï¼ŒvLLMæå‡ºäº†PagedAttentionæŠ€æœ¯ï¼Œå°†KV CacheæŒ‰é¡µè¿›è¡Œç®¡ç†ï¼Œå®ç°äº†å†…å­˜çš„æŒ‰éœ€åˆ†é…å’Œé«˜æ•ˆåˆ©ç”¨ã€‚è¿™ç§è®¾è®¡ä¸ä»…æ˜¾è‘—é™ä½äº†å†…å­˜ç¢ç‰‡åŒ–é—®é¢˜ï¼Œè¿˜æ”¯æŒäº†åŠ¨æ€åºåˆ—é•¿åº¦å¤„ç†ï¼Œä½¿å¾—å†…å­˜åˆ©ç”¨ç‡ç›¸æ¯”ä¼ ç»Ÿæ–¹æ¡ˆæå‡äº†æ•°å€ã€‚

**Continuous Batching(è¿ç»­æ‰¹å¤„ç†)**ï¼šä¼ ç»Ÿçš„é™æ€æ‰¹å¤„ç†æ–¹å¼å­˜åœ¨ä¸¥é‡çš„è®¡ç®—èµ„æºæµªè´¹é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å½“æ‰¹å†…åºåˆ—é•¿åº¦å·®å¼‚è¾ƒå¤§æ—¶ã€‚vLLMçš„è¿ç»­æ‰¹å¤„ç†æŠ€æœ¯æ”¯æŒåºåˆ—çš„åŠ¨æ€åŠ å…¥å’Œå®Œæˆï¼Œå®ç°äº†çœŸæ­£çš„æµæ°´çº¿å¼å¤„ç†ï¼Œå¤§å¹…æå‡äº†ç³»ç»Ÿååé‡å’Œèµ„æºåˆ©ç”¨æ•ˆç‡ã€‚

**Prefix Caching(å‰ç¼€ç¼“å­˜)**ï¼šåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¾ˆå¤šè¯·æ±‚å¾€å¾€å…±äº«ç›¸åŒçš„å‰ç¼€å†…å®¹ï¼ˆå¦‚ç³»ç»Ÿæç¤ºè¯ã€æ¨¡æ¿ç­‰ï¼‰ã€‚vLLMé€šè¿‡æ™ºèƒ½çš„å‰ç¼€ç¼“å­˜æœºåˆ¶ï¼Œèƒ½å¤Ÿå¤ç”¨å·²è®¡ç®—çš„KV Cacheï¼Œé¿å…é‡å¤è®¡ç®—ï¼Œæ˜¾è‘—é™ä½äº†æ¨ç†å»¶è¿Ÿå’Œè®¡ç®—å¼€é”€ã€‚

**Speculative Decoding(æ¨æµ‹è§£ç )**ï¼šä¸ºäº†è¿›ä¸€æ­¥æå‡ç”Ÿæˆé€Ÿåº¦ï¼ŒvLLMé›†æˆäº†æ¨æµ‹è§£ç æŠ€æœ¯ï¼Œé€šè¿‡ä½¿ç”¨è¾ƒå°çš„draftæ¨¡å‹é¢„å…ˆç”Ÿæˆå€™é€‰tokenï¼Œç„¶åç”±ä¸»æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼Œå®ç°äº†åœ¨ä¿è¯è¾“å‡ºè´¨é‡çš„å‰æä¸‹å¤§å¹…åŠ é€Ÿæ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ã€‚

**åˆ†å¸ƒå¼æ¶æ„ä¸å¤šGPUååŒ**ï¼šé¢å¯¹å¤§æ¨¡å‹å‚æ•°é‡ä¸æ–­å¢é•¿çš„è¶‹åŠ¿ï¼ŒvLLMæä¾›äº†å®Œå–„çš„åˆ†å¸ƒå¼è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒå¼ é‡å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œç­‰å¤šç§å¹¶è¡Œç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨å¤šGPUã€å¤šèŠ‚ç‚¹ç¯å¢ƒä¸‹å®ç°é«˜æ•ˆçš„æ¨¡å‹æ¨ç†ï¼Œæ»¡è¶³å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒçš„æ€§èƒ½éœ€æ±‚ã€‚

**åŠ¨æ€æ‰©ç¼©å®¹ä¸æœåŠ¡åŒ–**ï¼šä½œä¸ºä¸€ä¸ªé¢å‘ç”Ÿäº§çš„æ¨ç†æ¡†æ¶ï¼ŒvLLMä¸ä»…å…³æ³¨æ€§èƒ½ä¼˜åŒ–ï¼Œè¿˜æä¾›äº†å®Œæ•´çš„æœåŠ¡åŒ–èƒ½åŠ›ï¼ŒåŒ…æ‹¬è¯·æ±‚è·¯ç”±ã€è´Ÿè½½å‡è¡¡ã€è‡ªåŠ¨æ‰©ç¼©å®¹ç­‰åŠŸèƒ½ï¼Œä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿè½»æ¾æ„å»ºé«˜å¯ç”¨ã€é«˜æ€§èƒ½çš„LLMæœåŠ¡é›†ç¾¤ã€‚

é€šè¿‡å¯¹è¿™äº›å…³é”®æŠ€æœ¯çš„æ·±å…¥åˆ†æï¼Œæˆ‘ä»¬å°†å±•ç°vLLMå¦‚ä½•é€šè¿‡ç³»ç»Ÿæ€§çš„ä¼˜åŒ–è®¾è®¡ï¼Œåœ¨ä¿è¯æ¨ç†è´¨é‡çš„å‰æä¸‹ï¼Œå®ç°äº†ç›¸æ¯”ä¼ ç»Ÿæ–¹æ¡ˆæ•°å€ç”šè‡³æ•°åå€çš„æ€§èƒ½æå‡ã€‚è¿™äº›æŠ€æœ¯åˆ›æ–°ä¸ä»…æ¨åŠ¨äº†LLMæ¨ç†æœåŠ¡çš„å‘å±•ï¼Œä¹Ÿä¸ºæ•´ä¸ªAIåŸºç¡€è®¾æ–½é¢†åŸŸæä¾›äº†å®è´µçš„è®¾è®¡æ€è·¯å’Œå®è·µç»éªŒã€‚ä¸€å…±åˆ†ä¸ºäº”ä¸ªéƒ¨åˆ†ï¼š

â€¢ **LLM engine**ä»¥åŠ**engine core**ï¼šåŒ…å«äº†vLLMçš„åŸºç¡€æ¶æ„ï¼ˆè°ƒåº¦ã€PagedAttentionã€continous batchingï¼‰
â€¢ **Advanced Features é«˜çº§ç‰¹æ€§**ï¼šchunked prefill(åˆ†å—é¢„å¡«å……)ã€prefix caching(å‰ç¼€ç¼“å­˜)ã€guided&speculative decoding(å¼•å¯¼é¢„æµ‹ç¼–ç )ã€disaggregated P/D(Prefill-decodingåˆ†ç¦»)
â€¢ **Scaling Up**ï¼šå•è¿›ç¨‹æ‰§è¡Œåˆ°å¤šè¿›ç¨‹å¤šGPU
â€¢ **Server Layer**ï¼šåˆ†å¸ƒå¼é›†ç¾¤æœåŠ¡åŒ–éƒ¨ç½²
â€¢ **Benchmarks**ä¸**Auto-tuning**ï¼šå¹³è¡¡å»¶è¿Ÿå’Œåå

# LLM Engine & Engine Core

åœ¨vLLMä¸­ï¼ŒLLM Engineæ˜¯æœ€åŸºç¡€çš„blockï¼Œåœ¨ç¦»çº¿åœºæ™¯ä¸­ï¼Œå®ƒæœ¬èº«å°±æ”¯æŒé«˜ååœŸåœ°æ¨ç†ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„ç¦»çº¿æ¨ç†ä¾‹å­ï¼š

```Python
from vllm import LLM, SamplingParams

prompts = [
    "Hello, my name is",
    "The president of the United States is",
]

sampling_params = SamplingParams(temperature=0.8, top_p=0.95)

def main():
    llm = LLM(model="TinyLlama/TinyLlama-1.1B-Chat-v1.0")

    outputs = llm.generate(prompts, sampling_params)

if __name__ == "__main__":
    main()

## Environment vars:
##   VLLM_USE_V1="1" # we're using engine V1
##   VLLM_ENABLE_V1_MULTIPROCESSING="0" # we're running in a single process
## 
```

æˆ‘ä»¬è°ƒç”¨æ¨¡å‹æ‰§è¡Œå™¨çš„ `execute_model`ï¼Œå®ƒä¼šå§”æ´¾ç»™ `Worker`ï¼Œè€Œ `Worker` åˆä¼šç»§ç»­å§”æ´¾ç»™ `model runner`ã€‚

ä¸»è¦æ­¥éª¤å¦‚ä¸‹ï¼š

- **æ›´æ–°çŠ¶æ€** â€”â€” ä» `input_batch` ä¸­è£å‰ªå·²å®Œæˆçš„è¯·æ±‚ï¼›æ›´æ–°ä¸å‰å‘ä¼ æ’­ç›¸å…³çš„å…¶ä»–å…ƒæ•°æ®ï¼ˆä¾‹å¦‚æ¯ä¸ªè¯·æ±‚çš„ KV cache å—æ•°ï¼Œç”¨äºåœ¨åˆ†é¡µçš„ KV cache å†…å­˜ä¸­å»ºç«‹ç´¢å¼•ï¼‰ã€‚
- **å‡†å¤‡è¾“å…¥** â€”â€” å°†ç¼“å†²åŒºä» `CPUâ†’GPU` å¤åˆ¶ï¼›è®¡ç®—ä½ç½®ï¼›æ„å»º `slot_mapping`ï¼ˆç¤ºä¾‹ä¸­ä¼šè¯¦ç»†è¯´æ˜ï¼‰ï¼›æ„é€ æ³¨æ„åŠ›å…ƒæ•°æ®ã€‚
- **å‰å‘ä¼ æ’­** â€”â€” ä½¿ç”¨è‡ªå®šä¹‰çš„ PagedAttention å†…æ ¸è¿è¡Œæ¨¡å‹ã€‚æ‰€æœ‰åºåˆ—ä¼šè¢«å±•å¹³å¹¶è¿æ¥ä¸ºä¸€ä¸ªé•¿çš„â€œè¶…çº§åºåˆ—â€ã€‚ä½ç½®ç´¢å¼•ä¸æ³¨æ„åŠ›æ©ç ç¡®ä¿æ¯ä¸ªåºåˆ—åªå…³æ³¨è‡ªå·±çš„ tokenï¼Œä»è€Œåœ¨ä¸ä½¿ç”¨å³ä¾§å¡«å……çš„æƒ…å†µä¸‹å®ç°æŒç»­æ‰¹å¤„ç†ã€‚
- **æ”¶é›†æœ€åä¸€ä¸ª token çš„çŠ¶æ€** â€”â€” ä¸ºæ¯ä¸ªåºåˆ—çš„æœ€ç»ˆä½ç½®æå–éšè—çŠ¶æ€å¹¶è®¡ç®— `logits`ã€‚
- **é‡‡æ ·** â€”â€” æŒ‰ç…§é‡‡æ ·é…ç½®ï¼ˆè´ªå¿ƒã€æ¸©åº¦ã€`top-p`ã€`top-k` ç­‰ï¼‰ä»è®¡ç®—å‡ºçš„ `logits` ä¸­é‡‡æ · tokenã€‚

å‰å‘æ­¥éª¤æœ¬èº«æœ‰ä¸¤ç§æ‰§è¡Œæ¨¡å¼ï¼š

- **Eager æ¨¡å¼** â€”â€” åœ¨å¯ç”¨ eager æ‰§è¡Œæ—¶è¿è¡Œæ ‡å‡†çš„ PyTorch å‰å‘ä¼ æ’­ã€‚
- **â€œæ•è·â€æ¨¡å¼** â€”â€” åœ¨æœªå¼ºåˆ¶å¯ç”¨ eager çš„æƒ…å†µä¸‹ï¼Œæ‰§è¡Œæˆ–å›æ”¾é¢„å…ˆæ•è·çš„ CUDA Graphï¼ˆè¿˜è®°å¾—åœ¨å¼•æ“æ„å»ºçš„åˆå§‹åŒ– KV cache è¿‡ç¨‹ä¸­æˆ‘ä»¬å·²ç»æ•è·äº†å®ƒä»¬ï¼‰ã€‚

è¿™äº›é…ç½®æœ‰ï¼š

- ç¦»çº¿æ¨¡å¼ï¼ˆæ— WebæœåŠ¡æˆ–åˆ†å¸ƒå¼ç³»ç»Ÿæ¶æ„ï¼‰ï¼›
- åŒæ­¥æ‰§è¡Œï¼ˆæ‰€æœ‰æ‰§è¡Œéƒ½åœ¨å•ä¸ªé˜»å¡è¿›ç¨‹ä¸­è¿›è¡Œï¼‰ï¼›
- å•GPUï¼ˆæ— æ•°æ®/æ¨¡å‹/æµæ°´çº¿/ä¸“å®¶å¹¶è¡Œï¼›DP/TP/PP/EP = 1ï¼‰ï¼›
- ä½¿ç”¨æ ‡å‡†transformerç»“æ„ï¼ˆæ”¯æŒåƒJambaè¿™æ ·çš„æ··åˆæ¨¡å‹éœ€è¦æ›´å¤æ‚çš„æ··åˆKVç¼“å­˜å†…å­˜åˆ†é…å™¨ï¼‰ã€‚

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åšäº†ä¸¤ä»¶äº‹ï¼š
    1. å®ä¾‹åŒ–äº†ä¸€ä¸ªengineï¼›
    2. é€šè¿‡ç»™å®šçš„promptæ¥è°ƒç”¨ `generate` æ–¹æ³•å»åšé‡‡æ ·ã€‚

## LLM Engine constructor

å¯¹äºengineè€Œè¨€ï¼Œæ ¸å¿ƒçš„ç»„æˆéƒ¨åˆ†æœ‰ï¼š

  - vLLM configï¼šåŒ…å«æ¨¡å‹é…ç½®çš„å…¨éƒ¨ä¿¡æ¯ã€cacheã€å¹¶è¡Œç­–ç•¥ç­‰ï¼›
  - processerï¼šé€šè¿‡validationã€tokenizationå’Œprocessingå°† `raw input` -> `EngineCoreRequests`;
  - engine core clientï¼šåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ä½¿ç”¨äº† `InprocClient` ï¼ŒåŸºæœ¬ä¸Šç­‰äº `EngineCore` ï¼Œä¼šé€æ­¥æ­å»ºæˆ `DPLBAsyncMPClient` ï¼Œå…è®¸å¤§è§„æ¨¡æä¾›æœåŠ¡ï¼›
  - output processorï¼šå°† `raw EngineCoreOutputs` -> `RequestOutputs` è½¬æ¢ç»™ç”¨æˆ·çœ‹ã€‚

è‡³äº `EngineCore` æœ¬èº«ç”±ä»¥ä¸‹ç»„ä»¶ç»„æˆï¼š

- æ¨¡å‹æ‰§è¡Œå™¨ (Model Executor): é©±åŠ¨æ¨¡å‹çš„å‰å‘ä¼ æ’­ã€‚æˆ‘ä»¬ç›®å‰æ¥è§¦çš„æ˜¯åœ¨å•ä¸ªGPUä¸Šä½¿ç”¨å•ä¸ªWorkerè¿›ç¨‹çš„ `UniProcExecutor`ï¼Œåç»­ä¼šé€æ­¥æ‰©å±•åˆ°æ”¯æŒå¤šGPUçš„ `MultiProcExecutor`ã€‚
- ç»“æ„åŒ–è¾“å‡ºç®¡ç†å™¨ (Structured Output Manager): ç”¨äºå¼•å¯¼å¼è§£ç ï¼ˆç¨åä¼šè¯¦ç»†ä»‹ç»ï¼‰ã€‚
- è°ƒåº¦å™¨ (Scheduler): å†³å®šå“ªäº›è¯·æ±‚è¿›å…¥ä¸‹ä¸€ä¸ªå¼•æ“æ­¥éª¤ï¼Œå®ƒè¿›ä¸€æ­¥åŒ…å«ï¼š
    - ç­–ç•¥è®¾ç½® (policy setting): å¯ä»¥æ˜¯FCFSï¼ˆå…ˆåˆ°å…ˆå¾—ï¼‰æˆ–ä¼˜å…ˆçº§ï¼ˆé«˜ä¼˜å…ˆçº§è¯·æ±‚ä¼˜å…ˆå¤„ç†ï¼‰ã€‚
    - ç­‰å¾…å’Œè¿è¡Œé˜Ÿåˆ— (waiting and running queues)ã€‚
    - KVç¼“å­˜ç®¡ç†å™¨ (KV cache manager): PagedAttentionæœºåˆ¶çš„æ ¸å¿ƒã€‚

KV Cache Manager ç»´æŠ¤äº† `free_block_queue`ï¼Œä¹Ÿå°±æ˜¯å¯ç”¨çš„ KV Cache blocksç»„æˆçš„èµ„æºæ± ï¼›è§„æ¨¡å¾€å¾€èƒ½åˆ°å‡ åä¸‡ï¼Œå–å†³äºæ˜¾å­˜ä¸å—å¤§å°ã€‚å½“ PagedAttention æ‰§è¡Œæ—¶ï¼Œè¿™äº›å—æ‰¿æ‹…ç´¢å¼•ä½œç”¨ï¼Œå°†å„ä¸ª token å¯¹åº”åˆ°å®ƒä»¬çš„ KV Cache blockã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-1.png)


```
å…¶ä¸­å¯¹äºä¸€ä¸ªæ ‡å‡†transformerå±‚ï¼ˆéMLAï¼‰çš„block sizeå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¡ç®—ï¼š

2 (key/value) * block_size (default=16) * num_kv_heads * head_size * dtype_num_bytes (e.g. 2 for bf16)
```

å½“model excutoræ„å»ºæ—¶ï¼Œä¼šåˆ›å»ºä¸€ä¸ª `Worker` å¯¹è±¡ï¼Œå¹¶æ‰§è¡Œä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼ˆåœ¨ä½¿ç”¨ `MultiProcExecutor` æ—¶ï¼Œè¿™äº›æ­¥éª¤ä¼šåœ¨ä¸åŒ GPU ä¸Šçš„æ¯ä¸ª worker è¿›ç¨‹ä¸­ç‹¬ç«‹è¿è¡Œï¼‰ï¼š

- åˆå§‹åŒ–è®¾å¤‡:
    - ä¸ºè¯¥ worker åˆ†é… CUDA è®¾å¤‡ï¼ˆe.g. `cuda:0` ï¼‰ï¼Œå¹¶æ£€æŸ¥æ¨¡å‹çš„ dtype æ˜¯å¦å—æ”¯æŒï¼ˆe.g. `bf16` ï¼‰
    - æ ¹æ®è®¾å®šçš„ `gpu_memory_utilization` ï¼ˆe.g. 0.8 â†’ 80% of total VRAMï¼‰éªŒè¯æ˜¾å­˜æ˜¯å¦å……è¶³
    - é…ç½®åˆ†å¸ƒå¼è®¾ç½®ï¼ˆ DP / TP / PP / EP, etc.ï¼‰
    - å®ä¾‹åŒ– `model_runner` ï¼ˆåŒ…å«é‡‡æ ·å™¨ã€KV cacheï¼Œä»¥åŠforward passçš„bufferså¦‚ `input_ids` ã€ `positions`, etc.ï¼‰
    - å®ä¾‹åŒ– `InputBatch` å¯¹è±¡ï¼ˆåŒ…å« CPU-side forward pass bufferingã€KV cache indexingã€sampling metadataç­‰ï¼‰

- åŠ è½½æ¨¡å‹:
    - å®ä¾‹åŒ–æ¨¡å‹æ¶æ„
    - åŠ è½½æ¨¡å‹æƒé‡
    - è°ƒç”¨ `model.eval()` ï¼ˆPyTorch çš„æ¨ç†æ¨¡å¼ï¼‰
    - å¯é€‰ï¼šå¯¹æ¨¡å‹è°ƒç”¨ `torch.compile()`

- åˆå§‹åŒ– KV Cache:
    - è·å–æŒ‰å±‚çš„ KV cache specã€‚é€šå¸¸ä¸º `FullAttentionSpec` ï¼ˆåŒè´¨ Transformerï¼‰ï¼Œä½†åœ¨å¼•å…¥æ··åˆæ¨¡å‹ï¼ˆæ»‘åŠ¨çª—å£ã€Transformer/SSMï¼Œå¦‚ Jambaï¼‰åå˜å¾—æ›´å¤æ‚
    - è¿è¡Œä¸€æ¬¡dummy/profiling forward passï¼Œå¹¶è®°å½• GPU å†…å­˜å¿«ç…§ï¼Œç”¨äºè®¡ç®—åœ¨å¯ç”¨æ˜¾å­˜ä¸­èƒ½å®¹çº³å¤šå°‘ KV cache blocks
    - ä¸ºæ³¨æ„åŠ›å±‚åˆ†é…ã€reshapeå¹¶ç»‘å®š KV cache tensors
    - å‡†å¤‡ `attention metadata`ï¼ˆå¦‚å°†åç«¯è®¾ç½®ä¸º `FlashAttention` ï¼‰ï¼Œä¾›åç»­å‰å‘è¿‡ç¨‹ä¸­çš„å†…æ ¸ä½¿ç”¨
    - è‹¥æœªæä¾› `--enforce-eager` ï¼Œåˆ™é’ˆå¯¹è‹¥å¹²é¢„çƒ­æ‰¹å¤§å°è¿›è¡Œç©ºè·‘å¹¶æ•è· CUDA graphã€‚CUDA graphä¼šæŠŠæ•´æ®µ GPU å·¥ä½œè®°å½•ä¸ºä¸€ä¸ª DAGï¼›ä¹‹ååœ¨å‰å‘è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šå¯åŠ¨/å›æ”¾è¿™äº›é¢„å…ˆæ•è·ï¼ˆé¢„çƒ˜ç„™ï¼‰çš„ CUDA graphï¼Œå‰Šå‡ kernel å¯åŠ¨å¼€é”€ï¼Œå› è€Œæ—¶å»¶æ›´ä½ã€‚

æˆ‘ä»¬åœ¨è¿™é‡ŒæŠ½è±¡æ‰äº†è®¸å¤šåº•å±‚ç»†èŠ‚ï¼Œä½†ä»¥ä¸Šæ˜¯åæ–‡å°†åå¤å¼•ç”¨çš„æ ¸å¿ƒç»„ä»¶ä¸æµç¨‹ã€‚å¼•æ“åˆå§‹åŒ–å®Œæˆåï¼Œç»§ç»­è¿›å…¥ `generate` å‡½æ•°ã€‚

## Generate function

ç¬¬ä¸€æ­¥æ˜¯å¯¹è¯·æ±‚è¿›è¡Œæ ¡éªŒå¹¶é€å…¥ engine ã€‚å¯¹äºæ¯ä¸ª promptï¼Œæˆ‘ä»¬ä¼šï¼š

1. åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„è¯·æ±‚ IDï¼Œå¹¶è®°å½•å…¶åˆ°è¾¾æ—¶é—´ã€‚
2. è°ƒç”¨è¾“å…¥é¢„å¤„ç†å™¨å¯¹ prompt è¿›è¡Œæ ‡è®°åŒ–ï¼ˆtokenizeï¼‰ï¼Œè¿”å›ä¸€ä¸ªå­—å…¸ dictionaryï¼ŒåŒ…å« `prompt` ã€ `prompt_token_ids` ï¼Œä»¥åŠä¸€ä¸ª `type`ï¼ˆå¦‚ textã€tokensã€embeds, etc.ï¼‰ã€‚
3. å°†è¿™äº›ä¿¡æ¯æ‰“åŒ…æˆä¸€ä¸ª `EngineCoreRequest` ï¼Œå¹¶æ·»åŠ ä¼˜å…ˆçº§ã€é‡‡æ ·å‚æ•°åŠå…¶ä»–å…ƒæ•°æ®ã€‚
4. å°†è¯·æ±‚ä¼ å…¥ engine coreï¼Œcore ä¼šå°†å…¶åŒ…è£…ä¸ºä¸€ä¸ª `Request` å¯¹è±¡å¹¶å°†çŠ¶æ€è®¾ä¸º `WAITING` ï¼›éšåæŠŠè¯¥è¯·æ±‚åŠ å…¥è°ƒåº¦å™¨çš„ç­‰å¾…é˜Ÿåˆ—ï¼ˆè‹¥ä¸ºå…ˆæ¥å…ˆæœåŠ¡ FCFS åˆ™ä½¿ç”¨ appendï¼›è‹¥ä¸ºä¼˜å…ˆçº§è°ƒåº¦åˆ™ä½¿ç”¨ heap-pushï¼‰ã€‚

è‡³æ­¤ï¼Œå¼•æ“å·²ç»â€œè¿›æ–™â€ï¼Œæ‰§è¡Œå³å¯å¼€å§‹ã€‚åœ¨åŒæ­¥å¼•æ“ç¤ºä¾‹ä¸­ï¼Œåªä¼šå¤„ç†è¿™äº›åˆå§‹ promptâ€”â€”è¿è¡Œè¿‡ç¨‹ä¸­æ— æ³•æ’å…¥æ–°è¯·æ±‚ã€‚ç›¸åï¼Œå¼‚æ­¥å¼•æ“æ”¯æŒåœ¨è¿è¡Œä¸­æ³¨å…¥è¯·æ±‚ï¼ˆå³â€œæŒç»­æ‰¹å¤„ç†â€ continuous batchingï¼‰ï¼šåœ¨æ¯ä¸€æ­¥ä¹‹åï¼ŒåŒæ—¶è€ƒè™‘æ–°è¯·æ±‚ä¸å·²æœ‰è¯·æ±‚ã€‚

```
å‰å‘ä¼ æ’­å°† batch æ‰å¹³åŒ–ä¸ºå•åºåˆ—ï¼Œé…åˆé«˜æ•ˆçš„å®šåˆ¶ kernel å¤„ç†è·¯å¾„ï¼Œä½¿å¾—å³ä½¿åœ¨åŒæ­¥å¼•æ“ä¸­ä¹Ÿå¤©ç„¶å…·å¤‡ continuous batching èƒ½åŠ›ã€‚
```

æ¥ä¸‹æ¥ï¼Œåªè¦ä»æœ‰è¯·æ±‚å¾…å¤„ç†ï¼Œå¼•æ“å°±ä¼šåå¤è°ƒç”¨ `step()` å‡½æ•°ã€‚æ¯ä¸€æ­¥åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š
- è°ƒåº¦ï¼ˆScheduleï¼‰ï¼šé€‰æ‹©æœ¬æ­¥è¦è¿è¡Œçš„è¯·æ±‚ï¼ˆ decode ï¼Œand/or (chunked) prefill ï¼‰ã€‚
- å‰å‘ä¼ æ’­ï¼ˆForward passï¼‰ï¼šè¿è¡Œæ¨¡å‹å¹¶è¿›è¡Œ token é‡‡æ ·ã€‚
- åå¤„ç†ï¼ˆPostprocessï¼‰ï¼šå°†é‡‡æ ·å¾—åˆ°çš„ token ID è¿½åŠ åˆ°å„ä¸ª `Request` ï¼Œæ‰§è¡Œåæ ‡è®°åŒ–ï¼ˆ`detokenize`ï¼‰ï¼Œå¹¶æ£€æŸ¥åœæ­¢æ¡ä»¶ã€‚è‹¥æŸä¸ªè¯·æ±‚å·²å®Œæˆï¼Œåˆ™è¿›è¡Œæ¸…ç†ï¼ˆä¾‹å¦‚æŠŠå®ƒçš„ KV Cache block å½’è¿˜åˆ° `free_block_queue` ï¼‰ï¼Œå¹¶æå‰è¿”å›è¯¥è¯·æ±‚çš„è¾“å‡ºã€‚

ğŸ“ åœæ­¢æ¡ä»¶åŒ…æ‹¬ï¼š
- è¯·æ±‚è¶…è¿‡é•¿åº¦ä¸Šé™ï¼ˆ `max_model_length` æˆ–å…¶è‡ªèº«çš„ `max_tokens` ï¼‰ã€‚
- é‡‡æ ·åˆ° EOS IDï¼ˆé™¤éå¯ç”¨äº† `ignore_eos` â†’ åœ¨ benchmarking ä¸­å¯ç”¨äºå¼ºåˆ¶ç”Ÿæˆå›ºå®šæ•°é‡çš„è¾“å‡º tokenï¼‰ã€‚
- é‡‡æ ·åˆ°çš„ token åŒ¹é…åˆ°é‡‡æ ·å‚æ•°ä¸­æŒ‡å®šçš„ä»»æ„ `stop_token_ids` ã€‚
- è¾“å‡ºä¸­å‡ºç°åœæ­¢å­—ç¬¦ä¸²ï¼ˆstop stringsï¼‰â€”â€”æˆ‘ä»¬ä¼šå°†è¾“å‡ºæˆªæ–­åˆ°é¦–æ¬¡å‡ºç°åœæ­¢å­—ç¬¦ä¸²çš„ä½ç½®ï¼Œå¹¶åœ¨å¼•æ“ä¸­ç»ˆæ­¢è¯¥è¯·æ±‚ï¼ˆæ³¨æ„ï¼š stop_token_ids ä¼šä¿ç•™åœ¨è¾“å‡ºä¸­ï¼Œè€Œåœæ­¢å­—ç¬¦ä¸²ä¸ä¼šä¿ç•™ï¼‰ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-2.png)

åœ¨æµå¼æ¨¡å¼ä¸­ï¼Œæˆ‘ä»¬ä¼šåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å®æ—¶å‘é€ä¸­é—´ tokenï¼Œä½†è¿™é‡Œæš‚ä¸å±•å¼€ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ›´è¯¦ç»†åœ°è®¨è®ºè°ƒåº¦ã€‚

## Scheduler

æ¨ç†å¼•æ“å¤„ç†ä¸¤ç§ä¸»è¦ç±»å‹çš„å·¥ä½œè´Ÿè½½ï¼š

- **Prefill è¯·æ±‚** ï¼š å¯¹æ‰€æœ‰ prompt token è¿›è¡Œå‰å‘ä¼ æ’­ã€‚è¿™äº›é€šå¸¸æ˜¯è®¡ç®—å¯†é›†å‹çš„ï¼ˆé˜ˆå€¼å–å†³äºç¡¬ä»¶å’Œprompté•¿åº¦ï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬ä»æœ€ç»ˆ token ä½ç½®çš„æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ª tokenã€‚
- **Decode è¯·æ±‚** ï¼š ä»…å¯¹æœ€æ–°çš„ token è¿›è¡Œå‰å‘ä¼ æ’­ã€‚æ‰€æœ‰è¾ƒæ—©çš„ KV å‘é‡å·²ç»è¢«ç¼“å­˜ã€‚è¿™äº›æ˜¯ `memory-bandwidth-bound` çš„ï¼Œå› ä¸ºæˆ‘ä»¬ä»ç„¶éœ€è¦åŠ è½½æ‰€æœ‰ LLM æƒé‡ï¼ˆå’Œ KV cacheï¼‰æ¥è®¡ç®—ä¸€ä¸ª tokenã€‚

V1 scheduler å¯ä»¥åœ¨åŒä¸€æ­¥éª¤ä¸­æ··åˆå¤„ç†ä¸¤ç§ç±»å‹çš„è¯·æ±‚ï¼Œè¿™å¾—ç›Šäºæ›´æ™ºèƒ½çš„è®¾è®¡é€‰æ‹©ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒV0 engine ä¸€æ¬¡åªèƒ½å¤„ç† prefill æˆ– decode ä¸­çš„ä¸€ç§ workloadã€‚

Scheduler ä¼˜å…ˆå¤„ç† decode è¯·æ±‚â€”â€”å³é‚£äº›å·²ç»åœ¨è¿è¡Œé˜Ÿåˆ—ä¸­çš„è¯·æ±‚ã€‚å¯¹äºæ¯ä¸ªè¿™æ ·çš„è¯·æ±‚ï¼Œå®ƒä¼šï¼š
1. è®¡ç®—è¦ç”Ÿæˆçš„æ–° token æ•°é‡ï¼ˆç”±äºæ¨æµ‹è§£ç å’Œå¼‚æ­¥è°ƒåº¦ï¼Œä¸æ€»æ˜¯ä¼šåœ¨ç¬¬ä¸€æ­¥åšè¿™äº›äº‹æƒ…ï¼Œâ€”â€”ç¨åä¼šè¯¦ç»†ä»‹ç»ï¼‰ã€‚
2. è°ƒç”¨ KV cache manager çš„ `allocate_slots` å‡½æ•°ï¼ˆè¯¦ç»†ä¿¡æ¯è§ä¸‹æ–‡ï¼‰ã€‚
3. æ›´æ–° token budgetï¼šä¸æ–­å‡å°‘ç¬¬ 1 æ­¥è®¡ç®—å¾—åˆ°çš„ token æ•°é‡ã€‚

ä¹‹åï¼Œå®ƒå¤„ç†ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ prefill è¯·æ±‚ï¼š
1. æ£€ç´¢å·²è®¡ç®—å—çš„æ•°é‡ï¼ˆå¦‚æœç¦ç”¨å‰ç¼€ç¼“å­˜åˆ™è¿”å› 0â€”â€”ç¨åä¼šä»‹ç»ï¼‰ã€‚
2. è°ƒç”¨ KV cache manager çš„ `allocate_slots` å‡½æ•°ã€‚
3. å°†è¯·æ±‚ä»ç­‰å¾…é˜Ÿåˆ—ä¸­å¼¹å‡ºå¹¶ç§»åŠ¨åˆ°è¿è¡Œé˜Ÿåˆ—ï¼Œå°†å…¶çŠ¶æ€è®¾ç½®ä¸º `RUNNING`ã€‚
4. æ›´æ–° token budgetã€‚

ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹ `allocate_slots` çš„ä½œç”¨ï¼š
1. **è®¡ç®—å—æ•°é‡** â€” ç¡®å®šå¿…é¡»åˆ†é…å¤šå°‘ä¸ªæ–°çš„ KV cache å—ï¼ˆnï¼‰ã€‚æ¯ä¸ªå—é»˜è®¤å­˜å‚¨ 16 ä¸ª tokenã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ª prefill è¯·æ±‚æœ‰ 17 ä¸ªæ–° tokenï¼Œæˆ‘ä»¬éœ€è¦ ceil(17/16) = 2 ä¸ªå—ã€‚
2. **æ£€æŸ¥å¯ç”¨æ€§** â€” å¦‚æœç®¡ç†å™¨æ± ä¸­æ²¡æœ‰è¶³å¤Ÿçš„å—ï¼Œåˆ™æå‰é€€å‡ºã€‚æ ¹æ®æ˜¯ decode è¿˜æ˜¯ prefill è¯·æ±‚ï¼Œå¼•æ“å¯èƒ½ä¼šå°è¯•é‡è®¡ç®—æŠ¢å ï¼ˆV0 ä¸­æ”¯æŒäº¤æ¢æŠ¢å ï¼‰ï¼Œé€šè¿‡é©±é€ä½ä¼˜å…ˆçº§è¯·æ±‚ï¼ˆè°ƒç”¨ `kv_cache_manager.free` å°† KV å—è¿”å›åˆ°å—æ± ï¼‰ï¼Œæˆ–è€…å¯èƒ½è·³è¿‡è°ƒåº¦å¹¶ç»§ç»­æ‰§è¡Œã€‚
3. **åˆ†é…å—** â€” é€šè¿‡ KV cache manager çš„åè°ƒå™¨ï¼Œä»å—æ± ï¼ˆå‰é¢æåˆ°çš„ `free_block_queue` åŒå‘é“¾è¡¨ï¼‰ä¸­è·å–å‰ n ä¸ªå—ã€‚å­˜å‚¨åˆ° `req_to_blocks`ï¼Œè¿™æ˜¯å°†æ¯ä¸ª `request_id` æ˜ å°„åˆ°å…¶ KV cache block listçš„å­—å…¸ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-3.png)

æœ€ç»ˆï¼Œæˆ‘ä»¬å‡†å¤‡å¥½åšä¸€æ¬¡å‰å‘ä¼ é€’äº†ã€‚

## Run Forward pass

æˆ‘ä»¬è°ƒç”¨æ¨¡å‹æ‰§è¡Œå™¨çš„ `execute_model`ï¼Œå®ƒä¼šå§”æ´¾ç»™ `Worker`ï¼Œè€Œ `Worker` åˆè¿›ä¸€æ­¥å§”æ´¾ç»™ `model runner`ã€‚

ä¸»è¦æ­¥éª¤å¦‚ä¸‹ï¼š

- **æ›´æ–°çŠ¶æ€** â€”â€” ä» `input_batch` ä¸­è£å‰ªå·²å®Œæˆçš„è¯·æ±‚ï¼›æ›´æ–°ä¸å‰å‘ä¼ æ’­ç›¸å…³çš„å…¶ä»–å…ƒæ•°æ®ï¼ˆä¾‹å¦‚æ¯ä¸ªè¯·æ±‚çš„ KV cache å—æ•°ï¼Œç”¨äºåœ¨åˆ†é¡µçš„ KV cache å†…å­˜ä¸­å»ºç«‹ç´¢å¼•ï¼‰ã€‚
- **å‡†å¤‡è¾“å…¥** â€”â€” å°†ç¼“å†²åŒºä» `CPUâ†’GPU` å¤åˆ¶ï¼›è®¡ç®—ä½ç½®ï¼›æ„å»º `slot_mapping`ï¼ˆç¤ºä¾‹ä¸­ä¼šè¯¦ç»†è¯´æ˜ï¼‰ï¼›æ„é€ æ³¨æ„åŠ›å…ƒæ•°æ®ã€‚
- **å‰å‘ä¼ æ’­** â€”â€” ä½¿ç”¨è‡ªå®šä¹‰çš„ PagedAttention å†…æ ¸è¿è¡Œæ¨¡å‹ã€‚æ‰€æœ‰åºåˆ—ä¼šè¢«å±•å¹³å¹¶æ‹¼æ¥ä¸ºä¸€ä¸ªé•¿çš„â€œè¶…çº§åºåˆ—â€ã€‚ä½ç½®ç´¢å¼•ä¸æ³¨æ„åŠ›æ©ç ç¡®ä¿æ¯ä¸ªåºåˆ—åªå…³æ³¨è‡ªèº«çš„ tokenï¼Œä»è€Œåœ¨ä¸è¿›è¡Œå³ä¾§å¡«å……çš„æƒ…å†µä¸‹å®ç° continuous batchingã€‚
- **æ”¶é›†æœ€åä¸€ä¸ª token çš„çŠ¶æ€** â€”â€” ä¸ºæ¯ä¸ªåºåˆ—çš„æœ€ç»ˆä½ç½®æå–éšè—çŠ¶æ€å¹¶è®¡ç®— `logits`ã€‚
- **é‡‡æ ·** â€”â€” æŒ‰ç…§é‡‡æ ·é…ç½®ï¼ˆgreedyã€temperatureã€top-pã€top-k ç­‰ï¼‰ä»è®¡ç®—å¾—åˆ°çš„ `logits` ä¸­é‡‡æ · tokenã€‚

å‰å‘æ­¥éª¤æœ¬èº«æœ‰ä¸¤ç§æ‰§è¡Œæ¨¡å¼ï¼š

- **Eager Mode* â€”â€” å¯ç”¨ eager æ‰§è¡Œæ—¶è¿è¡Œæ ‡å‡†çš„ PyTorch å‰å‘ä¼ æ’­ã€‚
- **â€œCaptureâ€ Mode** â€”â€” åœ¨æœªå¼ºåˆ¶å¯ç”¨ eager çš„æƒ…å†µä¸‹ï¼Œæ‰§è¡Œ/å›æ”¾é¢„å…ˆæ•è·çš„ CUDA Graphï¼ˆè¿˜è®°å¾—æˆ‘ä»¬åœ¨å¼•æ“æ„å»ºçš„åˆå§‹åŒ– KV cache è¿‡ç¨‹ä¸­å·²æ•è·è¿™äº› graphï¼‰ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªå…·ä½“ç¤ºä¾‹ï¼Œå¯å¸®åŠ©ä½ æ›´æ¸…æ™°åœ°ç†è§£ continuous batching å’Œ PagedAttentionï¼š

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-4.png)

# Advanced Features â€” extending the core engine logic

åœ¨æŒæ¡åŸºæœ¬çš„å¼•æ“æµç¨‹åï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­äº†è§£ä¸€äº›é«˜çº§ç‰¹æ€§ã€‚

æˆ‘ä»¬å·²ç»è®¨è®ºäº†æŠ¢å ï¼ˆpreemptionï¼‰ã€PagedAttention å’Œ continuous batchingã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ·±å…¥è®²è§£ï¼š

- Chunked prefill
- Prefix caching
- Guided decoding
- Speculative decoding
- Disaggregated P/D

## Chunked prefill

Chunked prefillï¼ˆåˆ†å—å¼ prefillï¼‰æ˜¯ä¸€ç§é€šè¿‡å°†é•¿ prompt çš„ prefill æ­¥éª¤æ‹†åˆ†ä¸ºæ›´å°çš„ chunk æ¥å¤„ç†é•¿ prompt çš„æŠ€æœ¯ã€‚è‹¥ä¸ä½¿ç”¨è¯¥æ–¹æ³•ï¼Œä¸€ä¸ªéå¸¸é•¿çš„è¯·æ±‚å¯èƒ½ä¼šåœ¨æŸæ¬¡ `engine step` ä¸­é•¿æ—¶é—´ç‹¬å æ‰§è¡Œï¼Œé˜»æ­¢å…¶ä»– prefill è¯·æ±‚è¿è¡Œï¼Œä»è€Œæ¨è¿Ÿæ‰€æœ‰å…¶ä»–è¯·æ±‚å¹¶æ˜¾è‘—æé«˜å®ƒä»¬çš„å»¶è¿Ÿã€‚

ä¾‹å¦‚ï¼Œä»¤æ¯ä¸ª chunk åŒ…å« n (=8) ä¸ª tokenï¼Œå¹¶ç”¨å°å†™å­—æ¯ä»¥ â€œ-â€ åˆ†éš”æ¥æ ‡è®°ã€‚ä¸€ä¸ªé•¿æç¤º `P` å¯ä»¥è¡¨ç¤ºä¸º `x-y-z`ï¼Œå…¶ä¸­ `z` æ˜¯æœªå®Œæˆçš„ chunkï¼ˆä¾‹å¦‚ä»…åŒ…å« 2 ä¸ª tokensï¼‰ã€‚æ‰§è¡Œ `P` çš„å®Œæ•´ prefill è‡³å°‘éœ€è¦ â‰¥ 3 ä¸ª `engine step`ï¼ˆå¦‚æœæŸä¸€æ­¥æœªè¢«è°ƒåº¦æ‰§è¡Œï¼Œè¿˜å¯èƒ½éœ€è¦æ›´å¤šï¼‰ï¼Œå¹¶ä¸”åªæœ‰åœ¨æœ€åä¸€ä¸ªåˆ†å— prefill æ­¥éª¤ä¸­æˆ‘ä»¬æ‰ä¼šé‡‡æ ·ä¸€ä¸ªæ–° tokenã€‚

ä»¥ä¸‹æ˜¯åŒä¸€ç¤ºä¾‹çš„å¯è§†åŒ–è¯´æ˜ï¼š

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-5.png)

å®ç°å¾ˆç›´æ¥ï¼šä¸ºæ¯ä¸ª engine step è®¾å®šâ€œæ–°å¢ token æ•°é‡â€çš„ä¸Šé™ã€‚å½“è¯·æ±‚çš„æ•°é‡è¶…è¿‡ `long_prefill_token_threshold` æ—¶ï¼Œå°†å…¶é‡ç½®ä¸ºè¯¥é˜ˆå€¼ã€‚å…¶ä½™æµç¨‹ç”±åº•å±‚çš„ç´¢å¼•é€»è¾‘ï¼ˆå‰æ–‡å·²è¿°ï¼‰è‡ªåŠ¨å¤„ç†ã€‚

åœ¨ vLLM V1 ä¸­ï¼Œé€šè¿‡å°† `long_prefill_token_threshold` è®¾ç½®ä¸ºæ­£æ•´æ•°å³å¯å¯ç”¨ chunked prefillã€‚ï¼ˆä»æŠ€æœ¯ä¸Šè®²ï¼Œå³ä½¿æœªæ˜¾å¼è®¾ç½®ä¹Ÿå¯èƒ½å‘ç”Ÿï¼šè‹¥ prompt é•¿åº¦è¶…è¿‡ token é¢„ç®—ï¼Œæˆ‘ä»¬ä¼šå…ˆæˆªæ–­å®ƒï¼Œå¹¶ä»¥åˆ†å— prefill çš„æ–¹å¼è¿è¡Œã€‚ï¼‰

## Prefix Caching

ä¸ºäº†è§£é‡Š prefix caching çš„å·¥ä½œåŸç†ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹ä»£ç ï¼š

```python
from vllm import LLM, SamplingParams

long_prefix = "<a piece of text that is encoded into more than block_size tokens>"

prompts = [
    "Hello, my name is",
    "The president of the United States is",
]

sampling_params = SamplingParams(temperature=0.8, top_p=0.95)

def main():
    llm = LLM(model="TinyLlama/TinyLlama-1.1B-Chat-v1.0")

    outputs = llm.generate(long_prefix + prompts[0], sampling_params)
    outputs = llm.generate(long_prefix + prompts[1], sampling_params)

if __name__ == "__main__":
    main()
```
Prefix caching ç”¨äºé¿å…å¯¹å¤šä¸ª prompt å…±äº«çš„å¼€å¤´éƒ¨åˆ†é‡å¤è®¡ç®—ï¼ˆå› æ­¤ç§°ä¸º **â€œå‰ç¼€ Prefixâ€** ï¼‰ã€‚

å…³é”®åœ¨äº `long_prefix`ï¼šå®ƒè¢«å®šä¹‰ä¸ºé•¿åº¦è¶…è¿‡ä¸€ä¸ª KV cache block çš„å‰ç¼€ï¼ˆé»˜è®¤æ¯å— 16 tokensï¼‰ã€‚ä¸ºç®€åŒ–ç¤ºä¾‹ï¼Œå‡è®¾ `long_prefix` çš„é•¿åº¦æ°å¥½ä¸º `n Ã— block_size`ï¼ˆå…¶ä¸­ `n â‰¥ 1`ï¼‰ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒå¿…é¡»ä¸å—è¾¹ç•Œå®Œå…¨å¯¹é½â€”â€”å¦åˆ™æˆ‘ä»¬å¿…é¡»é‡æ–°è®¡ç®— `long_prefix_len % block_size` ä¸ª tokensï¼Œå› ä¸ºä¸å®Œæ•´çš„å—æ— æ³•è¢«ç¼“å­˜ã€‚è‹¥ä¸ä½¿ç”¨ prefix cachingï¼Œæ¯æ¬¡å¤„ç†ä¸€ä¸ªå…·æœ‰ç›¸åŒ `long_prefix` çš„æ–°è¯·æ±‚æ—¶ï¼Œéƒ½è¦é‡æ–°è®¡ç®—è¿™ `n Ã— block_size` ä¸ª tokensã€‚

è€Œä½¿ç”¨ prefix caching æ—¶ï¼Œè¿™äº› tokens åªéœ€è®¡ç®—ä¸€æ¬¡ï¼ˆå…¶ KV å­˜å…¥åˆ†é¡µçš„ `KV cache` å†…å­˜ï¼‰å¹¶è¢«å¤ç”¨ï¼Œå› æ­¤ä»…éœ€å¤„ç†æ–°çš„ prompt tokensã€‚è¿™ä¼šæ˜¾è‘—åŠ é€Ÿ prefill è¯·æ±‚ï¼ˆä½†å¯¹ decode æ— å¸®åŠ©ï¼‰ã€‚

é‚£ä¹ˆåœ¨ vLLM ä¸­å¦‚ä½•å·¥ä½œï¼Ÿ

åœ¨é¦–æ¬¡ `generate` è°ƒç”¨çš„è°ƒåº¦é˜¶æ®µï¼Œ`kv_cache_manager.get_computed_blocks` å†…ï¼Œengine ä¼šè°ƒç”¨ `hash_request_tokens`ï¼š

- å°† `long_prefix + prompts[0]` æŒ‰ 16-token åˆ‡åˆ†ä¸º chunksã€‚
- å¯¹æ¯ä¸ªå®Œæ•´ chunk è®¡ç®—ä¸€ä¸ª hashï¼ˆä½¿ç”¨å†…å»º `hash` æˆ– `SHA-256`ï¼Œåè€…æ›´æ…¢ä½† hash å†²çªæ›´å°‘ï¼‰ã€‚è¯¥ hash ç»„åˆäº†ä¸Šä¸€å—çš„ hashã€å½“å‰ tokens ä»¥åŠå¯é€‰å…ƒæ•°æ®ã€‚å¯é€‰å…ƒæ•°æ®åŒ…æ‹¬ï¼š`MM hash`ã€`LoRA ID`ã€`cache salt`ï¼ˆæ³¨å…¥é¦–å—çš„ hashï¼Œä¿è¯åªæœ‰æºå¸¦è¯¥ `cache salt` çš„è¯·æ±‚èƒ½å¤ç”¨è¿™äº›å—ï¼‰ã€‚
- æ¯ä¸ªç»“æœä»¥ `BlockHash` å¯¹è±¡å­˜å‚¨ï¼ŒåŒ…å«å…¶ hash ä¸ token IDsï¼›å‡½æ•°è¿”å›ä¸€ä¸ª block hashes åˆ—è¡¨ã€‚

è¯¥åˆ—è¡¨å†™å…¥ `self.req_to_block_hashes[request_id]`ã€‚

éšåï¼Œengine è°ƒç”¨ `find_longest_cache_hit`ï¼Œæ£€æŸ¥è¿™äº› hash æ˜¯å¦å·²å­˜åœ¨äº `cached_block_hash_to_block` ä¸­ã€‚å¯¹äºé¦–ä¸ªè¯·æ±‚ï¼Œé€šå¸¸ä¸ä¼šæœ‰å‘½ä¸­ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-6.png)


ç„¶åæˆ‘ä»¬è°ƒç”¨ `allocate_slots`ï¼Œå®ƒä¼šè¿›ä¸€æ­¥è°ƒç”¨ `coordinator.cache_blocks`ï¼Œå°†æ–°çš„ `BlockHash` æ¡ç›®ä¸å·²åˆ†é…çš„ `KV cache` blocks å…³è”ï¼Œå¹¶æŠŠæ˜ å°„è®°å½•åˆ° `cached_block_hash_to_block`ã€‚

éšåï¼Œå‰å‘ä¼ æ’­ä¼šåœ¨åˆ†é¡µçš„ `KV cache` å†…å­˜ä¸­å¡«å……å¯¹åº”çš„ KVï¼Œè¦†ç›–æˆ‘ä»¬ä¸Šé¢åˆ†é…çš„è¿™äº› `KV cache` blocksã€‚

åœ¨ç»å†å¤šä¸ª `engine step` åï¼Œç³»ç»Ÿä¼šç»§ç»­åˆ†é…æ›´å¤š `KV cache` blocksã€‚ä½†åœ¨æœ¬ç¤ºä¾‹ä¸­è¿™å¹¶ä¸é‡è¦ï¼Œå› ä¸ºå‰ç¼€åœ¨ `long_prefix` ä¹‹åå°±ç«‹å³å‘ç”Ÿäº†å·®å¼‚ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-7.png)

ç¬¬äºŒæ¬¡ä»¥ç›¸åŒå‰ç¼€è°ƒç”¨ `generate` æ—¶ï¼Œå‰è¿°æ­¥éª¤ 1â€“3 ä¼šå†æ¬¡æ‰§è¡Œï¼Œä½†æ­¤æ—¶ `find_longest_cache_hit` ä¼šï¼ˆé€šè¿‡çº¿æ€§æœç´¢ï¼‰ä¸ºå…¨éƒ¨ `n` ä¸ªå—æ‰¾åˆ°å‘½ä¸­ï¼Œengine å¯ç›´æ¥å¤ç”¨è¿™äº› `KV cache` blocksã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-8.png)


## Guided Decoding (FSM)


## Speculative Decoding

## Disaggregated P/D

# From UniprocExecutor to MultiProcExecutor

# Distributed system serving vLLM

## On the headless server node

## On the API server node

# Benchmarks and auto-tuning - latency vs throughput

# Epilogue

# Acknowledgements

A huge thank you to Hyperstack for providing me with H100s for my experiments over the past year!

Thanks to Nick Hill (core vLLM contributor, RedHat), Mark Saroufim (PyTorch), Kyle Krannen (NVIDIA, Dynamo), and Ashish Vaswani for reading pre-release version of this blog post and providing feedback!

References
vLLM https://github.com/vllm-project/vllm
"Attention Is All You Need", https://arxiv.org/abs/1706.03762
"Efficient Memory Management for Large Language Model Serving with PagedAttention", https://arxiv.org/abs/2309.06180
"DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model", https://arxiv.org/abs/2405.04434
"Jenga: Effective Memory Management for Serving LLM with Heterogeneity", https://arxiv.org/abs/2503.18292
"Orca: A Distributed Serving System for Transformer-Based Generative Models", https://www.usenix.org/conference/osdi22/presentation/yu
"XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models", https://arxiv.org/abs/2411.15100
"Accelerating Large Language Model Decoding with Speculative Sampling", https://arxiv.org/abs/2302.01318
"EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty", https://arxiv.org/abs/2401.15077
"Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads", https://arxiv.org/abs/2401.10774
LMCache, https://github.com/LMCache/LMCache

