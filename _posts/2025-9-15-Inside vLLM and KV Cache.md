---

layout: post
tags: [LLM, NLP, AI Infra]
title: Inside vLLM and KV Cache
date: 2025-9-15
author: Kyrie Chen
comments: true
toc: true
pinned: false

---

éšç€å¤§è¯­è¨€æ¨¡å‹(LLM)åœ¨å„ä¸ªé¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼Œå¦‚ä½•é«˜æ•ˆåœ°éƒ¨ç½²å’Œæ¨ç†è¿™äº›æ¨¡å‹æˆä¸ºäº†ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„æ¨¡å‹æ¨ç†æœåŠ¡å¾€å¾€é¢ä¸´ç€å†…å­˜åˆ©ç”¨ç‡ä½ã€ååé‡å—é™ã€å»¶è¿Ÿä¸å¯æ§ç­‰é—®é¢˜ï¼Œè¿™äº›ç“¶é¢ˆä¸¥é‡åˆ¶çº¦äº†LLMåœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„è§„æ¨¡åŒ–åº”ç”¨ã€‚vLLMä½œä¸ºä¸€ä¸ªä¸“ä¸ºLLMä¼˜åŒ–çš„é«˜æ€§èƒ½æ¨ç†æœåŠ¡æ¡†æ¶ï¼Œé€šè¿‡ä¸€ç³»åˆ—åˆ›æ–°çš„æŠ€æœ¯æ–¹æ¡ˆï¼Œæœ‰æ•ˆè§£å†³äº†è¿™äº›ç—›ç‚¹é—®é¢˜ã€‚

æœ¬æ–‡å°†æ·±å…¥å‰–ævLLMçš„æ ¸å¿ƒæ¶æ„å’Œå…³é”®æŠ€æœ¯å®ç°ï¼Œä»åº•å±‚çš„å†…å­˜ç®¡ç†æœºåˆ¶åˆ°ä¸Šå±‚çš„æœåŠ¡è°ƒåº¦ç­–ç•¥ï¼Œå…¨é¢è§£æå…¶å¦‚ä½•å®ç°é«˜æ•ˆçš„LLMæ¨ç†æœåŠ¡ã€‚æˆ‘ä»¬å°†é‡ç‚¹æ¢è®¨ä»¥ä¸‹å‡ ä¸ªæ ¸å¿ƒæŠ€æœ¯æ¨¡å—ï¼š

**PagedAttentionæœºåˆ¶**ï¼šå€Ÿé‰´æ“ä½œç³»ç»Ÿä¸­è™šæ‹Ÿå†…å­˜ç®¡ç†çš„æ€æƒ³ï¼ŒvLLMæå‡ºäº†PagedAttentionæŠ€æœ¯ï¼Œå°†KV CacheæŒ‰é¡µè¿›è¡Œç®¡ç†ï¼Œå®ç°äº†å†…å­˜çš„æŒ‰éœ€åˆ†é…å’Œé«˜æ•ˆåˆ©ç”¨ã€‚è¿™ç§è®¾è®¡ä¸ä»…æ˜¾è‘—é™ä½äº†å†…å­˜ç¢ç‰‡åŒ–é—®é¢˜ï¼Œè¿˜æ”¯æŒäº†åŠ¨æ€åºåˆ—é•¿åº¦å¤„ç†ï¼Œä½¿å¾—å†…å­˜åˆ©ç”¨ç‡ç›¸æ¯”ä¼ ç»Ÿæ–¹æ¡ˆæå‡äº†æ•°å€ã€‚

**Continuous Batching(è¿ç»­æ‰¹å¤„ç†)**ï¼šä¼ ç»Ÿçš„é™æ€æ‰¹å¤„ç†æ–¹å¼å­˜åœ¨ä¸¥é‡çš„è®¡ç®—èµ„æºæµªè´¹é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å½“æ‰¹å†…åºåˆ—é•¿åº¦å·®å¼‚è¾ƒå¤§æ—¶ã€‚vLLMçš„è¿ç»­æ‰¹å¤„ç†æŠ€æœ¯æ”¯æŒåºåˆ—çš„åŠ¨æ€åŠ å…¥å’Œå®Œæˆï¼Œå®ç°äº†çœŸæ­£çš„æµæ°´çº¿å¼å¤„ç†ï¼Œå¤§å¹…æå‡äº†ç³»ç»Ÿååé‡å’Œèµ„æºåˆ©ç”¨æ•ˆç‡ã€‚

**Prefix Caching(å‰ç¼€ç¼“å­˜)**ï¼šåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¾ˆå¤šè¯·æ±‚å¾€å¾€å…±äº«ç›¸åŒçš„å‰ç¼€å†…å®¹ï¼ˆå¦‚ç³»ç»Ÿæç¤ºè¯ã€æ¨¡æ¿ç­‰ï¼‰ã€‚vLLMé€šè¿‡æ™ºèƒ½çš„å‰ç¼€ç¼“å­˜æœºåˆ¶ï¼Œèƒ½å¤Ÿå¤ç”¨å·²è®¡ç®—çš„KV Cacheï¼Œé¿å…é‡å¤è®¡ç®—ï¼Œæ˜¾è‘—é™ä½äº†æ¨ç†å»¶è¿Ÿå’Œè®¡ç®—å¼€é”€ã€‚

**Speculative Decoding(æ¨æµ‹è§£ç )**ï¼šä¸ºäº†è¿›ä¸€æ­¥æå‡ç”Ÿæˆé€Ÿåº¦ï¼ŒvLLMé›†æˆäº†æ¨æµ‹è§£ç æŠ€æœ¯ï¼Œé€šè¿‡ä½¿ç”¨è¾ƒå°çš„draftæ¨¡å‹é¢„å…ˆç”Ÿæˆå€™é€‰tokenï¼Œç„¶åç”±ä¸»æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼Œå®ç°äº†åœ¨ä¿è¯è¾“å‡ºè´¨é‡çš„å‰æä¸‹å¤§å¹…åŠ é€Ÿæ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ã€‚

**åˆ†å¸ƒå¼æ¶æ„ä¸å¤šGPUååŒ**ï¼šé¢å¯¹å¤§æ¨¡å‹å‚æ•°é‡ä¸æ–­å¢é•¿çš„è¶‹åŠ¿ï¼ŒvLLMæä¾›äº†å®Œå–„çš„åˆ†å¸ƒå¼è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒå¼ é‡å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œç­‰å¤šç§å¹¶è¡Œç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨å¤šGPUã€å¤šèŠ‚ç‚¹ç¯å¢ƒä¸‹å®ç°é«˜æ•ˆçš„æ¨¡å‹æ¨ç†ï¼Œæ»¡è¶³å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒçš„æ€§èƒ½éœ€æ±‚ã€‚

**åŠ¨æ€æ‰©ç¼©å®¹ä¸æœåŠ¡åŒ–**ï¼šä½œä¸ºä¸€ä¸ªé¢å‘ç”Ÿäº§çš„æ¨ç†æ¡†æ¶ï¼ŒvLLMä¸ä»…å…³æ³¨æ€§èƒ½ä¼˜åŒ–ï¼Œè¿˜æä¾›äº†å®Œæ•´çš„æœåŠ¡åŒ–èƒ½åŠ›ï¼ŒåŒ…æ‹¬è¯·æ±‚è·¯ç”±ã€è´Ÿè½½å‡è¡¡ã€è‡ªåŠ¨æ‰©ç¼©å®¹ç­‰åŠŸèƒ½ï¼Œä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿè½»æ¾æ„å»ºé«˜å¯ç”¨ã€é«˜æ€§èƒ½çš„LLMæœåŠ¡é›†ç¾¤ã€‚

é€šè¿‡å¯¹è¿™äº›å…³é”®æŠ€æœ¯çš„æ·±å…¥åˆ†æï¼Œæˆ‘ä»¬å°†å±•ç°vLLMå¦‚ä½•é€šè¿‡ç³»ç»Ÿæ€§çš„ä¼˜åŒ–è®¾è®¡ï¼Œåœ¨ä¿è¯æ¨ç†è´¨é‡çš„å‰æä¸‹ï¼Œå®ç°äº†ç›¸æ¯”ä¼ ç»Ÿæ–¹æ¡ˆæ•°å€ç”šè‡³æ•°åå€çš„æ€§èƒ½æå‡ã€‚è¿™äº›æŠ€æœ¯åˆ›æ–°ä¸ä»…æ¨åŠ¨äº†LLMæ¨ç†æœåŠ¡çš„å‘å±•ï¼Œä¹Ÿä¸ºæ•´ä¸ªAIåŸºç¡€è®¾æ–½é¢†åŸŸæä¾›äº†å®è´µçš„è®¾è®¡æ€è·¯å’Œå®è·µç»éªŒã€‚ä¸€å…±åˆ†ä¸ºäº”ä¸ªéƒ¨åˆ†ï¼š

â€¢ **LLM engine**ä»¥åŠ**engine core**ï¼šåŒ…å«äº†vLLMçš„åŸºç¡€æ¶æ„ï¼ˆè°ƒåº¦ã€PagedAttentionã€continous batchingï¼‰
â€¢ **Advanced Features é«˜çº§ç‰¹æ€§**ï¼šchunked prefill(åˆ†å—é¢„å¡«å……)ã€prefix caching(å‰ç¼€ç¼“å­˜)ã€guided&speculative decoding(å¼•å¯¼é¢„æµ‹ç¼–ç )ã€disaggregated P/D(Prefill-decodingåˆ†ç¦»)
â€¢ **Scaling Up**ï¼šå•è¿›ç¨‹æ‰§è¡Œåˆ°å¤šè¿›ç¨‹å¤šGPU
â€¢ **Server Layer**ï¼šåˆ†å¸ƒå¼é›†ç¾¤æœåŠ¡åŒ–éƒ¨ç½²
â€¢ **Benchmarks**ä¸**Auto-tuning**ï¼šå¹³è¡¡å»¶è¿Ÿå’Œåå

# LLM Engine & Engine Core

åœ¨vLLMä¸­ï¼ŒLLM Engineæ˜¯æœ€åŸºç¡€çš„blockï¼Œåœ¨ç¦»çº¿åœºæ™¯ä¸­ï¼Œå®ƒæœ¬èº«å°±æ”¯æŒé«˜ååœŸåœ°æ¨ç†ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„ç¦»çº¿æ¨ç†ä¾‹å­ï¼š

```Python
from vllm import LLM, SamplingParams

prompts = [
    "Hello, my name is",
    "The president of the United States is",
]

sampling_params = SamplingParams(temperature=0.8, top_p=0.95)

def main():
    llm = LLM(model="TinyLlama/TinyLlama-1.1B-Chat-v1.0")

    outputs = llm.generate(prompts, sampling_params)

if __name__ == "__main__":
    main()

## Environment vars:
##   VLLM_USE_V1="1" # we're using engine V1
##   VLLM_ENABLE_V1_MULTIPROCESSING="0" # we're running in a single process
## 
```

æˆ‘ä»¬è°ƒç”¨æ¨¡å‹æ‰§è¡Œå™¨çš„ `execute_model`ï¼Œå®ƒä¼šå§”æ´¾ç»™ `Worker`ï¼Œè€Œ `Worker` åˆä¼šç»§ç»­å§”æ´¾ç»™ `model runner`ã€‚

ä¸»è¦æ­¥éª¤å¦‚ä¸‹ï¼š

- **æ›´æ–°çŠ¶æ€** â€”â€” ä» `input_batch` ä¸­è£å‰ªå·²å®Œæˆçš„è¯·æ±‚ï¼›æ›´æ–°ä¸å‰å‘ä¼ æ’­ç›¸å…³çš„å…¶ä»–metadataï¼ˆä¾‹å¦‚æ¯ä¸ªè¯·æ±‚çš„ KV cache å—æ•°ï¼Œç”¨äºåœ¨åˆ†é¡µçš„ KV cache å†…å­˜ä¸­å»ºç«‹ç´¢å¼•ï¼‰ã€‚
- **å‡†å¤‡è¾“å…¥** â€”â€” å°†ç¼“å†²åŒºä» `CPUâ†’GPU` å¤åˆ¶ï¼›è®¡ç®—ä½ç½®ï¼›æ„å»º `slot_mapping`ï¼ˆç¤ºä¾‹ä¸­ä¼šè¯¦ç»†è¯´æ˜ï¼‰ï¼›æ„é€ æ³¨æ„åŠ›metadataã€‚
- **å‰å‘ä¼ æ’­** â€”â€” ä½¿ç”¨è‡ªå®šä¹‰çš„ PagedAttention å†…æ ¸è¿è¡Œæ¨¡å‹ã€‚æ‰€æœ‰åºåˆ—ä¼šè¢«å±•å¹³å¹¶è¿æ¥ä¸ºä¸€ä¸ªé•¿çš„â€œè¶…çº§åºåˆ—â€ã€‚ä½ç½®ç´¢å¼•ä¸æ³¨æ„åŠ›æ©ç ç¡®ä¿æ¯ä¸ªåºåˆ—åªå…³æ³¨è‡ªå·±çš„ tokenï¼Œä»è€Œåœ¨ä¸ä½¿ç”¨å³ä¾§å¡«å……çš„æƒ…å†µä¸‹å®ç°æŒç»­æ‰¹å¤„ç†ã€‚
- **æ”¶é›†æœ€åä¸€ä¸ª token çš„çŠ¶æ€** â€”â€” ä¸ºæ¯ä¸ªåºåˆ—çš„æœ€ç»ˆä½ç½®æå–éšè—çŠ¶æ€å¹¶è®¡ç®— `logits`ã€‚
- **é‡‡æ ·** â€”â€” æŒ‰ç…§é‡‡æ ·é…ç½®ï¼ˆè´ªå¿ƒã€æ¸©åº¦ã€`top-p`ã€`top-k` ç­‰ï¼‰ä»è®¡ç®—å‡ºçš„ `logits` ä¸­é‡‡æ · tokenã€‚

å‰å‘æ­¥éª¤æœ¬èº«æœ‰ä¸¤ç§æ‰§è¡Œæ¨¡å¼ï¼š

- **Eager æ¨¡å¼** â€”â€” åœ¨å¯ç”¨ eager æ‰§è¡Œæ—¶è¿è¡Œæ ‡å‡†çš„ PyTorch å‰å‘ä¼ æ’­ã€‚
- **â€œæ•è·â€æ¨¡å¼** â€”â€” åœ¨æœªå¼ºåˆ¶å¯ç”¨ eager çš„æƒ…å†µä¸‹ï¼Œæ‰§è¡Œæˆ–å›æ”¾é¢„å…ˆæ•è·çš„ CUDA Graphï¼ˆè¿˜è®°å¾—åœ¨å¼•æ“æ„å»ºçš„åˆå§‹åŒ– KV cache è¿‡ç¨‹ä¸­æˆ‘ä»¬å·²ç»æ•è·äº†å®ƒä»¬ï¼‰ã€‚

è¿™äº›é…ç½®æœ‰ï¼š

- ç¦»çº¿æ¨¡å¼ï¼ˆæ— WebæœåŠ¡æˆ–åˆ†å¸ƒå¼ç³»ç»Ÿæ¶æ„ï¼‰ï¼›
- åŒæ­¥æ‰§è¡Œï¼ˆæ‰€æœ‰æ‰§è¡Œéƒ½åœ¨å•ä¸ªé˜»å¡è¿›ç¨‹ä¸­è¿›è¡Œï¼‰ï¼›
- å•GPUï¼ˆæ— æ•°æ®/æ¨¡å‹/æµæ°´çº¿/ä¸“å®¶å¹¶è¡Œï¼›DP/TP/PP/EP = 1ï¼‰ï¼›
- ä½¿ç”¨æ ‡å‡†transformerç»“æ„ï¼ˆæ”¯æŒåƒJambaè¿™æ ·çš„æ··åˆæ¨¡å‹éœ€è¦æ›´å¤æ‚çš„æ··åˆKVç¼“å­˜å†…å­˜åˆ†é…å™¨ï¼‰ã€‚

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åšäº†ä¸¤ä»¶äº‹ï¼š
    1. å®ä¾‹åŒ–äº†ä¸€ä¸ªengineï¼›
    2. é€šè¿‡ç»™å®šçš„promptæ¥è°ƒç”¨ `generate` æ–¹æ³•å»åšé‡‡æ ·ã€‚

## LLM Engine constructor

å¯¹äºengineè€Œè¨€ï¼Œæ ¸å¿ƒçš„ç»„æˆéƒ¨åˆ†æœ‰ï¼š

  - vLLM configï¼šåŒ…å«æ¨¡å‹é…ç½®çš„å…¨éƒ¨ä¿¡æ¯ã€cacheã€å¹¶è¡Œç­–ç•¥ç­‰ï¼›
  - processerï¼šé€šè¿‡validationã€tokenizationå’Œprocessingå°† `raw input` -> `EngineCoreRequests`;
  - engine core clientï¼šåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ä½¿ç”¨äº† `InprocClient` ï¼ŒåŸºæœ¬ä¸Šç­‰äº `EngineCore` ï¼Œä¼šé€æ­¥æ­å»ºæˆ `DPLBAsyncMPClient` ï¼Œå…è®¸å¤§è§„æ¨¡æä¾›æœåŠ¡ï¼›
  - output processorï¼šå°† `raw EngineCoreOutputs` -> `RequestOutputs` è½¬æ¢ç»™ç”¨æˆ·çœ‹ã€‚

è‡³äº `EngineCore` æœ¬èº«ç”±ä»¥ä¸‹ç»„ä»¶ç»„æˆï¼š

- æ¨¡å‹æ‰§è¡Œå™¨ (Model Executor): é©±åŠ¨æ¨¡å‹çš„å‰å‘ä¼ æ’­ã€‚æˆ‘ä»¬ç›®å‰æ¥è§¦çš„æ˜¯åœ¨å•ä¸ªGPUä¸Šä½¿ç”¨å•ä¸ªWorkerè¿›ç¨‹çš„ `UniProcExecutor`ï¼Œåç»­ä¼šé€æ­¥æ‰©å±•åˆ°æ”¯æŒå¤šGPUçš„ `MultiProcExecutor`ã€‚
- ç»“æ„åŒ–è¾“å‡ºç®¡ç†å™¨ (Structured Output Manager): ç”¨äºå¼•å¯¼å¼è§£ç ï¼ˆç¨åä¼šè¯¦ç»†ä»‹ç»ï¼‰ã€‚
- è°ƒåº¦å™¨ (Scheduler): å†³å®šå“ªäº›è¯·æ±‚è¿›å…¥ä¸‹ä¸€ä¸ªå¼•æ“æ­¥éª¤ï¼Œå®ƒè¿›ä¸€æ­¥åŒ…å«ï¼š
    - ç­–ç•¥è®¾ç½® (policy setting): å¯ä»¥æ˜¯FCFSï¼ˆå…ˆåˆ°å…ˆå¾—ï¼‰æˆ–ä¼˜å…ˆçº§ï¼ˆé«˜ä¼˜å…ˆçº§è¯·æ±‚ä¼˜å…ˆå¤„ç†ï¼‰ã€‚
    - ç­‰å¾…å’Œè¿è¡Œé˜Ÿåˆ— (waiting and running queues)ã€‚
    - KVç¼“å­˜ç®¡ç†å™¨ (KV cache manager): PagedAttentionæœºåˆ¶çš„æ ¸å¿ƒã€‚

KV Cache Manager ç»´æŠ¤äº† `free_block_queue`ï¼Œä¹Ÿå°±æ˜¯å¯ç”¨çš„ KV Cache blocksç»„æˆçš„èµ„æºæ± ï¼›è§„æ¨¡å¾€å¾€èƒ½åˆ°å‡ åä¸‡ï¼Œå–å†³äºæ˜¾å­˜ä¸å—å¤§å°ã€‚å½“ PagedAttention æ‰§è¡Œæ—¶ï¼Œè¿™äº›å—æ‰¿æ‹…ç´¢å¼•ä½œç”¨ï¼Œå°†å„ä¸ª token å¯¹åº”åˆ°å®ƒä»¬çš„ KV Cache blockã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-1.png)


```
å…¶ä¸­å¯¹äºä¸€ä¸ªæ ‡å‡†transformerå±‚ï¼ˆéMLAï¼‰çš„block sizeå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¡ç®—ï¼š

2 (key/value) * block_size (default=16) * num_kv_heads * head_size * dtype_num_bytes (e.g. 2 for bf16)
```

å½“model excutoræ„å»ºæ—¶ï¼Œä¼šåˆ›å»ºä¸€ä¸ª `Worker` å¯¹è±¡ï¼Œå¹¶æ‰§è¡Œä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼ˆåœ¨ä½¿ç”¨ `MultiProcExecutor` æ—¶ï¼Œè¿™äº›æ­¥éª¤ä¼šåœ¨ä¸åŒ GPU ä¸Šçš„æ¯ä¸ª worker è¿›ç¨‹ä¸­ç‹¬ç«‹è¿è¡Œï¼‰ï¼š

- åˆå§‹åŒ–è®¾å¤‡:
    - ä¸ºè¯¥ worker åˆ†é… CUDA è®¾å¤‡ï¼ˆe.g. `cuda:0` ï¼‰ï¼Œå¹¶æ£€æŸ¥æ¨¡å‹çš„ dtype æ˜¯å¦å—æ”¯æŒï¼ˆe.g. `bf16` ï¼‰
    - æ ¹æ®è®¾å®šçš„ `gpu_memory_utilization` ï¼ˆe.g. 0.8 â†’ 80% of total VRAMï¼‰éªŒè¯æ˜¾å­˜æ˜¯å¦å……è¶³
    - é…ç½®åˆ†å¸ƒå¼è®¾ç½®ï¼ˆ DP / TP / PP / EP, etc.ï¼‰
    - å®ä¾‹åŒ– `model_runner` ï¼ˆåŒ…å«é‡‡æ ·å™¨ã€KV cacheï¼Œä»¥åŠforward passçš„bufferså¦‚ `input_ids` ã€ `positions`, etc.ï¼‰
    - å®ä¾‹åŒ– `InputBatch` å¯¹è±¡ï¼ˆåŒ…å« CPU-side forward pass bufferingã€KV cache indexingã€sampling metadataç­‰ï¼‰

- åŠ è½½æ¨¡å‹:
    - å®ä¾‹åŒ–æ¨¡å‹æ¶æ„
    - åŠ è½½æ¨¡å‹æƒé‡
    - è°ƒç”¨ `model.eval()` ï¼ˆPyTorch çš„æ¨ç†æ¨¡å¼ï¼‰
    - å¯é€‰ï¼šå¯¹æ¨¡å‹è°ƒç”¨ `torch.compile()`

- åˆå§‹åŒ– KV Cache:
    - è·å–æŒ‰å±‚çš„ KV cache specã€‚é€šå¸¸ä¸º `FullAttentionSpec` ï¼ˆåŒè´¨ Transformerï¼‰ï¼Œä½†åœ¨å¼•å…¥æ··åˆæ¨¡å‹ï¼ˆæ»‘åŠ¨çª—å£ã€Transformer/SSMï¼Œå¦‚ Jambaï¼‰åå˜å¾—æ›´å¤æ‚
    - è¿è¡Œä¸€æ¬¡dummy/profiling forward passï¼Œå¹¶è®°å½• GPU å†…å­˜å¿«ç…§ï¼Œç”¨äºè®¡ç®—åœ¨å¯ç”¨æ˜¾å­˜ä¸­èƒ½å®¹çº³å¤šå°‘ KV cache blocks
    - ä¸ºæ³¨æ„åŠ›å±‚åˆ†é…ã€reshapeå¹¶ç»‘å®š KV cache tensors
    - å‡†å¤‡ `attention metadata`ï¼ˆå¦‚å°†åç«¯è®¾ç½®ä¸º `FlashAttention` ï¼‰ï¼Œä¾›åç»­å‰å‘è¿‡ç¨‹ä¸­çš„å†…æ ¸ä½¿ç”¨
    - è‹¥æœªæä¾› `--enforce-eager` ï¼Œåˆ™é’ˆå¯¹è‹¥å¹²é¢„çƒ­æ‰¹å¤§å°è¿›è¡Œç©ºè·‘å¹¶æ•è· CUDA graphã€‚CUDA graphä¼šæŠŠæ•´æ®µ GPU å·¥ä½œè®°å½•ä¸ºä¸€ä¸ª DAGï¼›ä¹‹ååœ¨å‰å‘è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šå¯åŠ¨/å›æ”¾è¿™äº›é¢„å…ˆæ•è·ï¼ˆé¢„çƒ˜ç„™ï¼‰çš„ CUDA graphï¼Œå‰Šå‡ kernel å¯åŠ¨å¼€é”€ï¼Œå› è€Œæ—¶å»¶æ›´ä½ã€‚

æˆ‘ä»¬åœ¨è¿™é‡ŒæŠ½è±¡æ‰äº†è®¸å¤šåº•å±‚ç»†èŠ‚ï¼Œä½†ä»¥ä¸Šæ˜¯åæ–‡å°†åå¤å¼•ç”¨çš„æ ¸å¿ƒç»„ä»¶ä¸æµç¨‹ã€‚å¼•æ“åˆå§‹åŒ–å®Œæˆåï¼Œç»§ç»­è¿›å…¥ `generate` å‡½æ•°ã€‚

## Generate function

ç¬¬ä¸€æ­¥æ˜¯å¯¹è¯·æ±‚è¿›è¡Œæ ¡éªŒå¹¶é€å…¥ engine ã€‚å¯¹äºæ¯ä¸ª promptï¼Œæˆ‘ä»¬ä¼šï¼š

1. åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„è¯·æ±‚ IDï¼Œå¹¶è®°å½•å…¶åˆ°è¾¾æ—¶é—´ã€‚
2. è°ƒç”¨è¾“å…¥é¢„å¤„ç†å™¨å¯¹ prompt è¿›è¡Œæ ‡è®°åŒ–ï¼ˆtokenizeï¼‰ï¼Œè¿”å›ä¸€ä¸ªå­—å…¸ dictionaryï¼ŒåŒ…å« `prompt` ã€ `prompt_token_ids` ï¼Œä»¥åŠä¸€ä¸ª `type`ï¼ˆå¦‚ textã€tokensã€embeds, etc.ï¼‰ã€‚
3. å°†è¿™äº›ä¿¡æ¯æ‰“åŒ…æˆä¸€ä¸ª `EngineCoreRequest` ï¼Œå¹¶æ·»åŠ ä¼˜å…ˆçº§ã€é‡‡æ ·å‚æ•°åŠå…¶ä»–metadataã€‚
4. å°†è¯·æ±‚ä¼ å…¥ engine coreï¼Œcore ä¼šå°†å…¶åŒ…è£…ä¸ºä¸€ä¸ª `Request` å¯¹è±¡å¹¶å°†çŠ¶æ€è®¾ä¸º `WAITING` ï¼›éšåæŠŠè¯¥è¯·æ±‚åŠ å…¥è°ƒåº¦å™¨çš„ç­‰å¾…é˜Ÿåˆ—ï¼ˆè‹¥ä¸ºå…ˆæ¥å…ˆæœåŠ¡ FCFS åˆ™ä½¿ç”¨ appendï¼›è‹¥ä¸ºä¼˜å…ˆçº§è°ƒåº¦åˆ™ä½¿ç”¨ heap-pushï¼‰ã€‚

è‡³æ­¤ï¼Œå¼•æ“å·²ç»â€œè¿›æ–™â€ï¼Œæ‰§è¡Œå³å¯å¼€å§‹ã€‚åœ¨åŒæ­¥å¼•æ“ç¤ºä¾‹ä¸­ï¼Œåªä¼šå¤„ç†è¿™äº›åˆå§‹ promptâ€”â€”è¿è¡Œè¿‡ç¨‹ä¸­æ— æ³•æ’å…¥æ–°è¯·æ±‚ã€‚ç›¸åï¼Œå¼‚æ­¥å¼•æ“æ”¯æŒåœ¨è¿è¡Œä¸­æ³¨å…¥è¯·æ±‚ï¼ˆå³â€œæŒç»­æ‰¹å¤„ç†â€ continuous batchingï¼‰ï¼šåœ¨æ¯ä¸€æ­¥ä¹‹åï¼ŒåŒæ—¶è€ƒè™‘æ–°è¯·æ±‚ä¸å·²æœ‰è¯·æ±‚ã€‚

```
å‰å‘ä¼ æ’­å°† batch æ‰å¹³åŒ–ä¸ºå•åºåˆ—ï¼Œé…åˆé«˜æ•ˆçš„å®šåˆ¶ kernel å¤„ç†è·¯å¾„ï¼Œä½¿å¾—å³ä½¿åœ¨åŒæ­¥å¼•æ“ä¸­ä¹Ÿå¤©ç„¶å…·å¤‡ continuous batching èƒ½åŠ›ã€‚
```

æ¥ä¸‹æ¥ï¼Œåªè¦ä»æœ‰è¯·æ±‚å¾…å¤„ç†ï¼Œå¼•æ“å°±ä¼šåå¤è°ƒç”¨ `step()` å‡½æ•°ã€‚æ¯ä¸€æ­¥åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š
- è°ƒåº¦ï¼ˆScheduleï¼‰ï¼šé€‰æ‹©æœ¬æ­¥è¦è¿è¡Œçš„è¯·æ±‚ï¼ˆ decode ï¼Œand/or (chunked) prefill ï¼‰ã€‚
- å‰å‘ä¼ æ’­ï¼ˆForward passï¼‰ï¼šè¿è¡Œæ¨¡å‹å¹¶è¿›è¡Œ token é‡‡æ ·ã€‚
- åå¤„ç†ï¼ˆPostprocessï¼‰ï¼šå°†é‡‡æ ·å¾—åˆ°çš„ token ID è¿½åŠ åˆ°å„ä¸ª `Request` ï¼Œæ‰§è¡Œåæ ‡è®°åŒ–ï¼ˆ`detokenize`ï¼‰ï¼Œå¹¶æ£€æŸ¥åœæ­¢æ¡ä»¶ã€‚è‹¥æŸä¸ªè¯·æ±‚å·²å®Œæˆï¼Œåˆ™è¿›è¡Œæ¸…ç†ï¼ˆä¾‹å¦‚æŠŠå®ƒçš„ KV Cache block å½’è¿˜åˆ° `free_block_queue` ï¼‰ï¼Œå¹¶æå‰è¿”å›è¯¥è¯·æ±‚çš„è¾“å‡ºã€‚

ğŸ“ åœæ­¢æ¡ä»¶åŒ…æ‹¬ï¼š
- è¯·æ±‚è¶…è¿‡é•¿åº¦ä¸Šé™ï¼ˆ `max_model_length` æˆ–å…¶è‡ªèº«çš„ `max_tokens` ï¼‰ã€‚
- é‡‡æ ·åˆ° EOS IDï¼ˆé™¤éå¯ç”¨äº† `ignore_eos` â†’ åœ¨ benchmarking ä¸­å¯ç”¨äºå¼ºåˆ¶ç”Ÿæˆå›ºå®šæ•°é‡çš„è¾“å‡º tokenï¼‰ã€‚
- é‡‡æ ·åˆ°çš„ token åŒ¹é…åˆ°é‡‡æ ·å‚æ•°ä¸­æŒ‡å®šçš„ä»»æ„ `stop_token_ids` ã€‚
- è¾“å‡ºä¸­å‡ºç°åœæ­¢å­—ç¬¦ä¸²ï¼ˆstop stringsï¼‰â€”â€”æˆ‘ä»¬ä¼šå°†è¾“å‡ºæˆªæ–­åˆ°é¦–æ¬¡å‡ºç°åœæ­¢å­—ç¬¦ä¸²çš„ä½ç½®ï¼Œå¹¶åœ¨å¼•æ“ä¸­ç»ˆæ­¢è¯¥è¯·æ±‚ï¼ˆæ³¨æ„ï¼š stop_token_ids ä¼šä¿ç•™åœ¨è¾“å‡ºä¸­ï¼Œè€Œåœæ­¢å­—ç¬¦ä¸²ä¸ä¼šä¿ç•™ï¼‰ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-2.png)

åœ¨æµå¼æ¨¡å¼ä¸­ï¼Œæˆ‘ä»¬ä¼šåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å®æ—¶å‘é€ä¸­é—´ tokenï¼Œä½†è¿™é‡Œæš‚ä¸å±•å¼€ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ›´è¯¦ç»†åœ°è®¨è®ºè°ƒåº¦ã€‚

## Scheduler

æ¨ç†å¼•æ“å¤„ç†ä¸¤ç§ä¸»è¦ç±»å‹çš„å·¥ä½œè´Ÿè½½ï¼š

- **Prefill è¯·æ±‚** ï¼š å¯¹æ‰€æœ‰ prompt token è¿›è¡Œå‰å‘ä¼ æ’­ã€‚è¿™äº›é€šå¸¸æ˜¯è®¡ç®—å¯†é›†å‹çš„ï¼ˆé˜ˆå€¼å–å†³äºç¡¬ä»¶å’Œprompté•¿åº¦ï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬ä»æœ€ç»ˆ token ä½ç½®çš„æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ª tokenã€‚
- **Decode è¯·æ±‚** ï¼š ä»…å¯¹æœ€æ–°çš„ token è¿›è¡Œå‰å‘ä¼ æ’­ã€‚æ‰€æœ‰è¾ƒæ—©çš„ KV å‘é‡å·²ç»è¢«ç¼“å­˜ã€‚è¿™äº›æ˜¯ `memory-bandwidth-bound` çš„ï¼Œå› ä¸ºæˆ‘ä»¬ä»ç„¶éœ€è¦åŠ è½½æ‰€æœ‰ LLM æƒé‡ï¼ˆå’Œ KV cacheï¼‰æ¥è®¡ç®—ä¸€ä¸ª tokenã€‚

V1 scheduler å¯ä»¥åœ¨åŒä¸€æ­¥éª¤ä¸­æ··åˆå¤„ç†ä¸¤ç§ç±»å‹çš„è¯·æ±‚ï¼Œè¿™å¾—ç›Šäºæ›´æ™ºèƒ½çš„è®¾è®¡é€‰æ‹©ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒV0 engine ä¸€æ¬¡åªèƒ½å¤„ç† prefill æˆ– decode ä¸­çš„ä¸€ç§ workloadã€‚

Scheduler ä¼˜å…ˆå¤„ç† decode è¯·æ±‚â€”â€”å³é‚£äº›å·²ç»åœ¨è¿è¡Œé˜Ÿåˆ—ä¸­çš„è¯·æ±‚ã€‚å¯¹äºæ¯ä¸ªè¿™æ ·çš„è¯·æ±‚ï¼Œå®ƒä¼šï¼š
1. è®¡ç®—è¦ç”Ÿæˆçš„æ–° token æ•°é‡ï¼ˆç”±äºæ¨æµ‹è§£ç å’Œå¼‚æ­¥è°ƒåº¦ï¼Œä¸æ€»æ˜¯ä¼šåœ¨ç¬¬ä¸€æ­¥åšè¿™äº›äº‹æƒ…ï¼Œâ€”â€”ç¨åä¼šè¯¦ç»†ä»‹ç»ï¼‰ã€‚
2. è°ƒç”¨ KV cache manager çš„ `allocate_slots` å‡½æ•°ï¼ˆè¯¦ç»†ä¿¡æ¯è§ä¸‹æ–‡ï¼‰ã€‚
3. æ›´æ–° token budgetï¼šä¸æ–­å‡å°‘ç¬¬ 1 æ­¥è®¡ç®—å¾—åˆ°çš„ token æ•°é‡ã€‚

ä¹‹åï¼Œå®ƒå¤„ç†ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ prefill è¯·æ±‚ï¼š
1. æ£€ç´¢å·²è®¡ç®—å—çš„æ•°é‡ï¼ˆå¦‚æœç¦ç”¨å‰ç¼€ç¼“å­˜åˆ™è¿”å› 0â€”â€”ç¨åä¼šä»‹ç»ï¼‰ã€‚
2. è°ƒç”¨ KV cache manager çš„ `allocate_slots` å‡½æ•°ã€‚
3. å°†è¯·æ±‚ä»ç­‰å¾…é˜Ÿåˆ—ä¸­å¼¹å‡ºå¹¶ç§»åŠ¨åˆ°è¿è¡Œé˜Ÿåˆ—ï¼Œå°†å…¶çŠ¶æ€è®¾ç½®ä¸º `RUNNING`ã€‚
4. æ›´æ–° token budgetã€‚

ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹ `allocate_slots` çš„ä½œç”¨ï¼š
1. **è®¡ç®—å—æ•°é‡** â€” ç¡®å®šå¿…é¡»åˆ†é…å¤šå°‘ä¸ªæ–°çš„ KV cache å—ï¼ˆnï¼‰ã€‚æ¯ä¸ªå—é»˜è®¤å­˜å‚¨ 16 ä¸ª tokenã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ª prefill è¯·æ±‚æœ‰ 17 ä¸ªæ–° tokenï¼Œæˆ‘ä»¬éœ€è¦ ceil(17/16) = 2 ä¸ªå—ã€‚
2. **æ£€æŸ¥å¯ç”¨æ€§** â€” å¦‚æœç®¡ç†å™¨æ± ä¸­æ²¡æœ‰è¶³å¤Ÿçš„å—ï¼Œåˆ™æå‰é€€å‡ºã€‚æ ¹æ®æ˜¯ decode è¿˜æ˜¯ prefill è¯·æ±‚ï¼Œå¼•æ“å¯èƒ½ä¼šå°è¯•é‡è®¡ç®—æŠ¢å ï¼ˆV0 ä¸­æ”¯æŒäº¤æ¢æŠ¢å ï¼‰ï¼Œé€šè¿‡é©±é€ä½ä¼˜å…ˆçº§è¯·æ±‚ï¼ˆè°ƒç”¨ `kv_cache_manager.free` å°† KV å—è¿”å›åˆ°å—æ± ï¼‰ï¼Œæˆ–è€…å¯èƒ½è·³è¿‡è°ƒåº¦å¹¶ç»§ç»­æ‰§è¡Œã€‚
3. **åˆ†é…å—** â€” é€šè¿‡ KV cache manager çš„åè°ƒå™¨ï¼Œä»å—æ± ï¼ˆå‰é¢æåˆ°çš„ `free_block_queue` åŒå‘é“¾è¡¨ï¼‰ä¸­è·å–å‰ n ä¸ªå—ã€‚å­˜å‚¨åˆ° `req_to_blocks`ï¼Œè¿™æ˜¯å°†æ¯ä¸ª `request_id` æ˜ å°„åˆ°å…¶ KV cache block listçš„å­—å…¸ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-3.png)

æœ€ç»ˆï¼Œæˆ‘ä»¬å‡†å¤‡å¥½åšä¸€æ¬¡å‰å‘ä¼ é€’äº†ã€‚

## Run Forward pass

æˆ‘ä»¬è°ƒç”¨æ¨¡å‹æ‰§è¡Œå™¨çš„ `execute_model`ï¼Œå®ƒä¼šå§”æ´¾ç»™ `Worker`ï¼Œè€Œ `Worker` åˆè¿›ä¸€æ­¥å§”æ´¾ç»™ `model runner`ã€‚

ä¸»è¦æ­¥éª¤å¦‚ä¸‹ï¼š

- **æ›´æ–°çŠ¶æ€** â€”â€” ä» `input_batch` ä¸­è£å‰ªå·²å®Œæˆçš„è¯·æ±‚ï¼›æ›´æ–°ä¸å‰å‘ä¼ æ’­ç›¸å…³çš„å…¶ä»–metadataï¼ˆä¾‹å¦‚æ¯ä¸ªè¯·æ±‚çš„ KV cache å—æ•°ï¼Œç”¨äºåœ¨åˆ†é¡µçš„ KV cache å†…å­˜ä¸­å»ºç«‹ç´¢å¼•ï¼‰ã€‚
- **å‡†å¤‡è¾“å…¥** â€”â€” å°†ç¼“å†²åŒºä» `CPUâ†’GPU` å¤åˆ¶ï¼›è®¡ç®—ä½ç½®ï¼›æ„å»º `slot_mapping`ï¼ˆç¤ºä¾‹ä¸­ä¼šè¯¦ç»†è¯´æ˜ï¼‰ï¼›æ„é€ æ³¨æ„åŠ›metadataã€‚
- **å‰å‘ä¼ æ’­** â€”â€” ä½¿ç”¨è‡ªå®šä¹‰çš„ PagedAttention å†…æ ¸è¿è¡Œæ¨¡å‹ã€‚æ‰€æœ‰åºåˆ—ä¼šè¢«å±•å¹³å¹¶æ‹¼æ¥ä¸ºä¸€ä¸ªé•¿çš„â€œè¶…çº§åºåˆ—â€ã€‚ä½ç½®ç´¢å¼•ä¸æ³¨æ„åŠ›æ©ç ç¡®ä¿æ¯ä¸ªåºåˆ—åªå…³æ³¨è‡ªèº«çš„ tokenï¼Œä»è€Œåœ¨ä¸è¿›è¡Œå³ä¾§å¡«å……çš„æƒ…å†µä¸‹å®ç° continuous batchingã€‚
- **æ”¶é›†æœ€åä¸€ä¸ª token çš„çŠ¶æ€** â€”â€” ä¸ºæ¯ä¸ªåºåˆ—çš„æœ€ç»ˆä½ç½®æå–éšè—çŠ¶æ€å¹¶è®¡ç®— `logits`ã€‚
- **é‡‡æ ·** â€”â€” æŒ‰ç…§é‡‡æ ·é…ç½®ï¼ˆgreedyã€temperatureã€top-pã€top-k ç­‰ï¼‰ä»è®¡ç®—å¾—åˆ°çš„ `logits` ä¸­é‡‡æ · tokenã€‚

å‰å‘æ­¥éª¤æœ¬èº«æœ‰ä¸¤ç§æ‰§è¡Œæ¨¡å¼ï¼š

- **Eager Mode* â€”â€” å¯ç”¨ eager æ‰§è¡Œæ—¶è¿è¡Œæ ‡å‡†çš„ PyTorch å‰å‘ä¼ æ’­ã€‚
- **â€œCaptureâ€ Mode** â€”â€” åœ¨æœªå¼ºåˆ¶å¯ç”¨ eager çš„æƒ…å†µä¸‹ï¼Œæ‰§è¡Œ/å›æ”¾é¢„å…ˆæ•è·çš„ CUDA Graphï¼ˆè¿˜è®°å¾—æˆ‘ä»¬åœ¨å¼•æ“æ„å»ºçš„åˆå§‹åŒ– KV cache è¿‡ç¨‹ä¸­å·²æ•è·è¿™äº› graphï¼‰ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªå…·ä½“ç¤ºä¾‹ï¼Œå¯å¸®åŠ©ä½ æ›´æ¸…æ™°åœ°ç†è§£ continuous batching å’Œ PagedAttentionï¼š

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-4.png)

# Advanced Features â€” extending the core engine logic

åœ¨æŒæ¡åŸºæœ¬çš„å¼•æ“æµç¨‹åï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­äº†è§£ä¸€äº›é«˜çº§ç‰¹æ€§ã€‚

æˆ‘ä»¬å·²ç»è®¨è®ºäº†æŠ¢å ï¼ˆpreemptionï¼‰ã€PagedAttention å’Œ continuous batchingã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ·±å…¥è®²è§£ï¼š

- Chunked prefill
- Prefix caching
- Guided decoding
- Speculative decoding
- Disaggregated P/D

## Chunked prefill

Chunked prefillï¼ˆåˆ†å—å¼ prefillï¼‰æ˜¯ä¸€ç§é€šè¿‡å°†é•¿ prompt çš„ prefill æ­¥éª¤æ‹†åˆ†ä¸ºæ›´å°çš„ chunk æ¥å¤„ç†é•¿ prompt çš„æŠ€æœ¯ã€‚è‹¥ä¸ä½¿ç”¨è¯¥æ–¹æ³•ï¼Œä¸€ä¸ªéå¸¸é•¿çš„è¯·æ±‚å¯èƒ½ä¼šåœ¨æŸæ¬¡ `engine step` ä¸­é•¿æ—¶é—´ç‹¬å æ‰§è¡Œï¼Œé˜»æ­¢å…¶ä»– prefill è¯·æ±‚è¿è¡Œï¼Œä»è€Œæ¨è¿Ÿæ‰€æœ‰å…¶ä»–è¯·æ±‚å¹¶æ˜¾è‘—æé«˜å®ƒä»¬çš„å»¶è¿Ÿã€‚

ä¾‹å¦‚ï¼Œä»¤æ¯ä¸ª chunk åŒ…å« n (=8) ä¸ª tokenï¼Œå¹¶ç”¨å°å†™å­—æ¯ä»¥ â€œ-â€ åˆ†éš”æ¥æ ‡è®°ã€‚ä¸€ä¸ªé•¿æç¤º `P` å¯ä»¥è¡¨ç¤ºä¸º `x-y-z`ï¼Œå…¶ä¸­ `z` æ˜¯æœªå®Œæˆçš„ chunkï¼ˆä¾‹å¦‚ä»…åŒ…å« 2 ä¸ª tokensï¼‰ã€‚æ‰§è¡Œ `P` çš„å®Œæ•´ prefill è‡³å°‘éœ€è¦ â‰¥ 3 ä¸ª `engine step`ï¼ˆå¦‚æœæŸä¸€æ­¥æœªè¢«è°ƒåº¦æ‰§è¡Œï¼Œè¿˜å¯èƒ½éœ€è¦æ›´å¤šï¼‰ï¼Œå¹¶ä¸”åªæœ‰åœ¨æœ€åä¸€ä¸ªåˆ†å— prefill æ­¥éª¤ä¸­æˆ‘ä»¬æ‰ä¼šé‡‡æ ·ä¸€ä¸ªæ–° tokenã€‚

ä»¥ä¸‹æ˜¯åŒä¸€ç¤ºä¾‹çš„å¯è§†åŒ–è¯´æ˜ï¼š

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-5.png)

å®ç°å¾ˆç›´æ¥ï¼šä¸ºæ¯ä¸ª engine step è®¾å®šâ€œæ–°å¢ token æ•°é‡â€çš„ä¸Šé™ã€‚å½“è¯·æ±‚çš„æ•°é‡è¶…è¿‡ `long_prefill_token_threshold` æ—¶ï¼Œå°†å…¶é‡ç½®ä¸ºè¯¥é˜ˆå€¼ã€‚å…¶ä½™æµç¨‹ç”±åº•å±‚çš„ç´¢å¼•é€»è¾‘ï¼ˆå‰æ–‡å·²è¿°ï¼‰è‡ªåŠ¨å¤„ç†ã€‚

åœ¨ vLLM V1 ä¸­ï¼Œé€šè¿‡å°† `long_prefill_token_threshold` è®¾ç½®ä¸ºæ­£æ•´æ•°å³å¯å¯ç”¨ chunked prefillã€‚ï¼ˆä»æŠ€æœ¯ä¸Šè®²ï¼Œå³ä½¿æœªæ˜¾å¼è®¾ç½®ä¹Ÿå¯èƒ½å‘ç”Ÿï¼šè‹¥ prompt é•¿åº¦è¶…è¿‡ token é¢„ç®—ï¼Œæˆ‘ä»¬ä¼šå…ˆæˆªæ–­å®ƒï¼Œå¹¶ä»¥åˆ†å— prefill çš„æ–¹å¼è¿è¡Œã€‚ï¼‰

## Prefix Caching

ä¸ºäº†è§£é‡Š prefix caching çš„å·¥ä½œåŸç†ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹ä»£ç ï¼š

```python
from vllm import LLM, SamplingParams

long_prefix = "<a piece of text that is encoded into more than block_size tokens>"

prompts = [
    "Hello, my name is",
    "The president of the United States is",
]

sampling_params = SamplingParams(temperature=0.8, top_p=0.95)

def main():
    llm = LLM(model="TinyLlama/TinyLlama-1.1B-Chat-v1.0")

    outputs = llm.generate(long_prefix + prompts[0], sampling_params)
    outputs = llm.generate(long_prefix + prompts[1], sampling_params)

if __name__ == "__main__":
    main()
```
Prefix caching ç”¨äºé¿å…å¯¹å¤šä¸ª prompt å…±äº«çš„å¼€å¤´éƒ¨åˆ†é‡å¤è®¡ç®—ï¼ˆå› æ­¤ç§°ä¸º **â€œå‰ç¼€ Prefixâ€** ï¼‰ã€‚

å…³é”®åœ¨äº `long_prefix`ï¼šå®ƒè¢«å®šä¹‰ä¸ºé•¿åº¦è¶…è¿‡ä¸€ä¸ª KV cache block çš„å‰ç¼€ï¼ˆé»˜è®¤æ¯å— 16 tokensï¼‰ã€‚ä¸ºç®€åŒ–ç¤ºä¾‹ï¼Œå‡è®¾ `long_prefix` çš„é•¿åº¦æ°å¥½ä¸º `n Ã— block_size`ï¼ˆå…¶ä¸­ `n â‰¥ 1`ï¼‰ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒå¿…é¡»ä¸å—è¾¹ç•Œå®Œå…¨å¯¹é½â€”â€”å¦åˆ™æˆ‘ä»¬å¿…é¡»é‡æ–°è®¡ç®— `long_prefix_len % block_size` ä¸ª tokensï¼Œå› ä¸ºä¸å®Œæ•´çš„å—æ— æ³•è¢«ç¼“å­˜ã€‚è‹¥ä¸ä½¿ç”¨ prefix cachingï¼Œæ¯æ¬¡å¤„ç†ä¸€ä¸ªå…·æœ‰ç›¸åŒ `long_prefix` çš„æ–°è¯·æ±‚æ—¶ï¼Œéƒ½è¦é‡æ–°è®¡ç®—è¿™ `n Ã— block_size` ä¸ª tokensã€‚

è€Œä½¿ç”¨ prefix caching æ—¶ï¼Œè¿™äº› tokens åªéœ€è®¡ç®—ä¸€æ¬¡ï¼ˆå…¶ KV å­˜å…¥åˆ†é¡µçš„ `KV cache` å†…å­˜ï¼‰å¹¶è¢«å¤ç”¨ï¼Œå› æ­¤ä»…éœ€å¤„ç†æ–°çš„ prompt tokensã€‚è¿™ä¼šæ˜¾è‘—åŠ é€Ÿ prefill è¯·æ±‚ï¼ˆä½†å¯¹ decode æ— å¸®åŠ©ï¼‰ã€‚

é‚£ä¹ˆåœ¨ vLLM ä¸­å¦‚ä½•å·¥ä½œï¼Ÿ

åœ¨é¦–æ¬¡ `generate` è°ƒç”¨çš„è°ƒåº¦é˜¶æ®µï¼Œ`kv_cache_manager.get_computed_blocks` å†…ï¼Œengine ä¼šè°ƒç”¨ `hash_request_tokens`ï¼š

- å°† `long_prefix + prompts[0]` æŒ‰ 16-token åˆ‡åˆ†ä¸º chunksã€‚
 - å¯¹æ¯ä¸ªå®Œæ•´ chunk è®¡ç®—ä¸€ä¸ª hashï¼ˆä½¿ç”¨å†…å»º `hash` æˆ– `SHA-256`ï¼Œåè€…æ›´æ…¢ä½† hash å†²çªæ›´å°‘ï¼‰ã€‚è¯¥ hash ç»„åˆäº†ä¸Šä¸€å—çš„ hashã€å½“å‰ tokens ä»¥åŠå¯é€‰metadataã€‚å¯é€‰metadataåŒ…æ‹¬ï¼š`MM hash`ã€`LoRA ID`ã€`cache salt`ï¼ˆæ³¨å…¥é¦–å—çš„ hashï¼Œä¿è¯åªæœ‰æºå¸¦è¯¥ `cache salt` çš„è¯·æ±‚èƒ½å¤ç”¨è¿™äº›å—ï¼‰ã€‚
- æ¯ä¸ªç»“æœä»¥ `BlockHash` å¯¹è±¡å­˜å‚¨ï¼ŒåŒ…å«å…¶ hash ä¸ token IDsï¼›å‡½æ•°è¿”å›ä¸€ä¸ª block hashes åˆ—è¡¨ã€‚

è¯¥åˆ—è¡¨å†™å…¥ `self.req_to_block_hashes[request_id]`ã€‚

éšåï¼Œengine è°ƒç”¨ `find_longest_cache_hit`ï¼Œæ£€æŸ¥è¿™äº› hash æ˜¯å¦å·²å­˜åœ¨äº `cached_block_hash_to_block` ä¸­ã€‚å¯¹äºé¦–ä¸ªè¯·æ±‚ï¼Œé€šå¸¸ä¸ä¼šæœ‰å‘½ä¸­ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-6.png)


ç„¶åæˆ‘ä»¬è°ƒç”¨ `allocate_slots`ï¼Œå®ƒä¼šè¿›ä¸€æ­¥è°ƒç”¨ `coordinator.cache_blocks`ï¼Œå°†æ–°çš„ `BlockHash` æ¡ç›®ä¸å·²åˆ†é…çš„ `KV cache` blocks å…³è”ï¼Œå¹¶æŠŠæ˜ å°„è®°å½•åˆ° `cached_block_hash_to_block`ã€‚

éšåï¼Œå‰å‘ä¼ æ’­ä¼šåœ¨åˆ†é¡µçš„ `KV cache` å†…å­˜ä¸­å¡«å……å¯¹åº”çš„ KVï¼Œè¦†ç›–æˆ‘ä»¬ä¸Šé¢åˆ†é…çš„è¿™äº› `KV cache` blocksã€‚

åœ¨ç»å†å¤šä¸ª `engine step` åï¼Œç³»ç»Ÿä¼šç»§ç»­åˆ†é…æ›´å¤š `KV cache` blocksã€‚ä½†åœ¨æœ¬ç¤ºä¾‹ä¸­è¿™å¹¶ä¸é‡è¦ï¼Œå› ä¸ºå‰ç¼€åœ¨ `long_prefix` ä¹‹åå°±ç«‹å³å‘ç”Ÿäº†å·®å¼‚ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-7.png)

ç¬¬äºŒæ¬¡ä»¥ç›¸åŒå‰ç¼€è°ƒç”¨ `generate` æ—¶ï¼Œå‰è¿°æ­¥éª¤ 1â€“3 ä¼šå†æ¬¡æ‰§è¡Œï¼Œä½†æ­¤æ—¶ `find_longest_cache_hit` ä¼šï¼ˆé€šè¿‡çº¿æ€§æœç´¢ï¼‰ä¸ºå…¨éƒ¨ `n` ä¸ªå—æ‰¾åˆ°å‘½ä¸­ï¼Œengine å¯ç›´æ¥å¤ç”¨è¿™äº› `KV cache` blocksã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-8.png)

å¦‚æœæœ€åˆçš„è¯·æ±‚ä»åœ¨è¿è¡Œï¼Œè¿™äº›å—çš„å¼•ç”¨è®¡æ•°ï¼ˆreference countï¼‰ä¼šå¢åŠ ï¼ˆä¾‹å¦‚å˜ä¸º 2ï¼‰ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œç¬¬ä¸€ä¸ªè¯·æ±‚å·²ç»å®Œæˆï¼Œå› æ­¤è¿™äº›å—è¢«é‡Šæ”¾å›åˆ°æ± ä¸­ï¼Œå…¶å¼•ç”¨è®¡æ•°é‡ç½®ä¸º 0ã€‚ç”±äºæˆ‘ä»¬èƒ½å¤Ÿä» `cached_block_hash_to_block` å–å›å®ƒä»¬ï¼Œè¡¨æ˜è¿™äº›å—ä»ç„¶æœ‰æ•ˆï¼ˆKV cache manager çš„é€»è¾‘å°±æ˜¯è¿™æ ·è®¾è®¡çš„ï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€å†æ¬¡å°†å®ƒä»¬ä» `free_block_queue` ä¸­ç§»é™¤å³å¯å¤ç”¨ã€‚

`KV cache` blocks åªæœ‰åœ¨å³å°†ä» `free_block_queue`ï¼ˆä»å·¦ç«¯å¼¹å‡ºï¼‰é‡æ–°åˆ†é…æ—¶æ‰ä¼šè¢«åˆ¤å®šä¸ºâ€œæ— æ•ˆâ€ã€‚æ­¤æ—¶å¦‚æœå‘ç°è¯¥å—ä»æœ‰å…³è”çš„ hash å¹¶å­˜åœ¨äº `cached_block_hash_to_block` ä¸­ï¼Œæˆ‘ä»¬ä¼šæ¸…é™¤è¯¥å—çš„ hashï¼Œå¹¶å°†å…¶ä» `cached_block_hash_to_block` ä¸­ç§»é™¤ï¼Œä»¥ç¡®ä¿å®ƒä¸èƒ½å†é€šè¿‡ prefix caching è¢«å¤ç”¨ï¼ˆè‡³å°‘ä¸èƒ½ç”¨äºæ—§çš„å‰ç¼€ï¼‰ã€‚

è¿™å°±æ˜¯ prefix caching çš„æ ¸å¿ƒï¼šä¸è¦é‡å¤è®¡ç®—å·²ç»è§è¿‡çš„å‰ç¼€â€”â€”ç›´æ¥å¤ç”¨å®ƒä»¬çš„ `KV cache`ï¼

å¦‚æœç†è§£äº†è¿™ä¸ªç¤ºä¾‹ï¼Œä¹Ÿå°±ç†è§£äº† PagedAttention çš„å·¥ä½œæ–¹å¼ã€‚

Prefix caching é»˜è®¤å¯ç”¨ã€‚è‹¥è¦å…³é—­ï¼šå°† `enable_prefix_caching = False`ã€‚

## Guided Decoding (FSM)

Guided decodingï¼ˆå¼•å¯¼å¼è§£ç ï¼‰æ˜¯ä¸€ç§åœ¨æ¯ä¸ªè§£ç æ­¥å¯¹ `logits` æ–½åŠ çº¦æŸçš„æŠ€æœ¯ï¼Œçº¦æŸç”±åŸºäºè¯­æ³•çš„æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰å®šä¹‰ã€‚è¿™ç¡®ä¿äº†åªä¼šé‡‡æ ·è¯­æ³•å…è®¸çš„ tokenã€‚

è¿™æ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„è®¾å®šï¼šä½ å¯ä»¥å¼ºåˆ¶æ‰§è¡Œä»æ­£åˆ™è¯­æ³•ï¼ˆChomsky type-3ï¼Œä¾‹å¦‚ä»»æ„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼‰åˆ°ä¸Šä¸‹æ–‡æ— å…³è¯­æ³•ï¼ˆtype-2ï¼Œè¦†ç›–å¤§å¤šæ•°ç¼–ç¨‹è¯­è¨€ï¼‰çš„ä¸€åˆ‡çº¦æŸã€‚

ä¸ºä½¿å…¶æ›´å…·ä½“ï¼Œæˆ‘ä»¬å…ˆä»æœ€ç®€å•çš„ç¤ºä¾‹å…¥æ‰‹ï¼Œå¹¶åœ¨å…ˆå‰çš„ä»£ç åŸºç¡€ä¸Šç»§ç»­æ„å»ºï¼š

```python
from vllm import LLM, SamplingParams
from vllm.sampling_params import GuidedDecodingParams

prompts = [
    "This sucks",
    "The weather is beautiful",
]

guided_decoding_params = GuidedDecodingParams(choice=["Positive", "Negative"])
sampling_params = SamplingParams(guided_decoding=guided_decoding_params)

def main():
    llm = LLM(model="TinyLlama/TinyLlama-1.1B-Chat-v1.0")

    outputs = llm.generate(prompts, sampling_params)

if __name__ == "__main__":
    main()
```

åœ¨ç»™å‡ºçš„ toy example ä¸­ï¼ˆå‡è®¾å­—ç¬¦çº§ tokenizationï¼‰ï¼šåœ¨ prefill é˜¶æ®µï¼ŒFSM ä¼šå¯¹ `logits` è¿›è¡Œæ©è”½ï¼Œä½¿å¾—åªæœ‰ â€œPâ€ æˆ– â€œNâ€ å¯ä»¥è¢«é‡‡æ ·ã€‚è‹¥é‡‡æ ·åˆ° â€œPâ€ï¼ŒFSM å°†è½¬å…¥ â€œPositiveâ€ åˆ†æ”¯ï¼›ä¸‹ä¸€æ­¥ä»…å…è®¸ â€œoâ€ï¼Œä¾æ­¤ç±»æ¨ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-9.png)

vLLM ä¸­çš„å·¥ä½œæ–¹å¼ï¼š

1. åœ¨æ„é€  LLM å¼•æ“æ—¶ï¼Œä¼šåˆ›å»º `StructuredOutputManager`ï¼›å®ƒå¯è®¿é—® tokenizerï¼Œå¹¶ç»´æŠ¤ä¸€ä¸ª `_grammar_bitmask` å¼ é‡ï¼›
2. å½“æ·»åŠ è¯·æ±‚æ—¶ï¼ŒçŠ¶æ€è¢«è®¾ç½®ä¸º `WAITING_FOR_FSM`ï¼Œ`grammar_init` ä¼šé€‰æ‹©åç«¯ç¼–è¯‘å™¨ï¼ˆä¾‹å¦‚ `xgrammar` ï¼Œè¿™é‡Œçš„å¤§éƒ¨åˆ†å¤æ‚åº¦éƒ½éšè—åœ¨è¯¸å¦‚ `xgrammar` ç­‰ç¬¬ä¸‰æ–¹åº“ä¸­ï¼‰ï¼›
3. é’ˆå¯¹è¯¥è¯·æ±‚çš„è¯­æ³•ä¼šå¼‚æ­¥ç¼–è¯‘ï¼›
4. åœ¨è°ƒåº¦è¿‡ç¨‹ä¸­ï¼Œå¦‚æœå¼‚æ­¥ç¼–è¯‘å·²å®Œæˆï¼ŒçŠ¶æ€åˆ‡æ¢ä¸º `WAITING`ï¼Œå¹¶å°† `request_id` åŠ å…¥ `structured_output_request_ids`ï¼›å¦åˆ™å°†å…¶æ”¾å…¥ `skipped_waiting_requests`ï¼Œåœ¨ä¸‹ä¸€æ¬¡å¼•æ“æ­¥ï¼ˆengine stepï¼‰é‡è¯•ã€‚
5. åœ¨è°ƒåº¦å¾ªç¯ç»“æŸåï¼ˆä»å¤„äºè°ƒåº¦é˜¶æ®µï¼‰ï¼Œå¦‚æœå­˜åœ¨ FSM è¯·æ±‚ï¼Œ`StructuredOutputManager` ä¼šè®©åç«¯å‡†å¤‡/æ›´æ–° `_grammar_bitmask`ã€‚
6. å½“å‰å‘ä¼ æ’­äº§ç”Ÿ `logits` åï¼Œ`xgr_torch_compile` çš„å‡½æ•°ä¼šå°†ä½æ©ç å±•å¼€åˆ°è¯è¡¨å¤§å°ï¼ˆç”±äºä½¿ç”¨ 32 ä½æ•´æ•°ï¼Œå±•å¼€æ¯”ä¾‹ä¸º 32Ã—ï¼‰ï¼Œå¹¶å°†ä¸å…è®¸çš„ `logits` ç½®ä¸º `-âˆ`ã€‚
7. åœ¨é‡‡æ ·ä¸‹ä¸€ä¸ª token ä¹‹åï¼Œé€šè¿‡ `accept_tokens` æ¨è¿›è¯¥è¯·æ±‚çš„ FSMã€‚ç›´è§‚ä¸Šæˆ‘ä»¬åœ¨ FSM å›¾ä¸Šç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªçŠ¶æ€ã€‚

å…¶ä¸­ç¬¬ 6 æ­¥å€¼å¾—è¿›ä¸€æ­¥æ¾„æ¸…ï¼š

è‹¥ `vocab_size = 32`ï¼Œ`_grammar_bitmask` æ˜¯ä¸€ä¸ªæ•´æ•°ï¼›å…¶äºŒè¿›åˆ¶è¡¨ç¤ºç¼–ç äº†å“ªäº› token è¢«å…è®¸ï¼ˆâ€œ1â€ï¼‰ä¸ä¸å…è®¸ï¼ˆâ€œ0â€ï¼‰ã€‚ä¾‹å¦‚ï¼Œâ€œ101â€¦001â€ä¼šå±•å¼€ä¸ºé•¿åº¦ä¸º 32 çš„æ•°ç»„ `[1, 0, 1, â€¦, 0, 0, 1]`ï¼›å€¼ä¸º 0 çš„ä½ç½®å¯¹åº”çš„ `logits` è¢«ç½®ä¸º `-âˆ`ã€‚

å¯¹æ›´å¤§çš„è¯è¡¨ï¼Œä¼šä½¿ç”¨å¤šä¸ª 32 ä½å­—ï¼Œå¹¶æŒ‰éœ€å±•å¼€/æ‹¼æ¥ã€‚åç«¯ï¼ˆä¾‹å¦‚ `xgrammar`ï¼‰è´Ÿè´£ä¾æ®å½“å‰ FSM çŠ¶æ€ç”Ÿæˆè¿™äº›ä½æ¨¡å¼ã€‚

ä»¥ä¸‹è¿˜æœ‰ä¸€ä¸ªæ›´ç®€å•çš„ç¤ºä¾‹ï¼š`vocab_size = 8` ä¸”ä½¿ç”¨ 8 ä½æ•´æ•°ï¼ˆé€‚åˆç»“åˆå¯è§†åŒ–æ¥ç†è§£ï¼‰ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-10.png)

åœ¨ vLLM ä¸­ï¼Œä½ å¯ä»¥é€šè¿‡ä¼ å…¥æ‰€éœ€çš„ `guided_decoding` é…ç½®æ¥å¯ç”¨è¯¥åŠŸèƒ½ã€‚

## Speculative Decoding

åœ¨è‡ªå›å½’ç”Ÿæˆï¼ˆautoregressive generationï¼‰ä¸­ï¼Œæ¯äº§ç”Ÿä¸€ä¸ªæ–° token éƒ½éœ€è¦å¯¹ LLM åšä¸€æ¬¡å‰å‘ä¼ æ’­ï¼ˆforward passï¼‰ã€‚è¿™ä¸ªæ“ä½œçš„è®¡ç®—å¼€é”€éå¸¸å¤§ï¼Œå› ä¸ºæ¯ä¸€æ­¥éƒ½è¦é‡æ–°åŠ è½½å¹¶åº”ç”¨å…¨éƒ¨æ¨¡å‹æƒé‡ï¼Œåªä¸ºè®¡ç®—ä¸€ä¸ª tokenï¼ï¼ˆå‡è®¾ `batch size == 1`ï¼Œæ›´ä¸€èˆ¬çš„æƒ…å†µæ˜¯ `B`ï¼‰

`Speculative decoding` é€šè¿‡å¼•å…¥ä¸€ä¸ªæ›´å°çš„ `â€œDraft LMâ€` æ¥åŠ é€Ÿã€‚Draft LM ä»¥æ›´ä½æˆæœ¬æå‡º `k` ä¸ª token çš„å€™é€‰ã€‚ä½†æˆ‘ä»¬å¹¶ä¸å¸Œæœ›æœ€ç»ˆä»è¿™ä¸ªå°æ¨¡å‹çš„ç»“æœä¸­ç›´æ¥é‡‡æ ·ï¼Œå› ä¸ºå®ƒåªæ˜¯ç”¨æ¥çŒœæµ‹å¯èƒ½çš„ç»­å†™ã€‚æˆ‘ä»¬æœ€ç»ˆçš„é‡‡æ ·ç»“æœä»ç”±å¤§å‹æ¨¡å‹æ¥å†³å®šå“ªäº›å€™é€‰æ˜¯æœ‰æ•ˆçš„ã€‚

å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š

1. **Draft** ï¼šä½¿ç”¨å°æ¨¡å‹åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸Šè¿è¡Œï¼Œæå‡º `k` ä¸ª tokenï¼›
2. **Verify** ï¼šä½¿ç”¨å¤§æ¨¡å‹åœ¨â€œä¸Šä¸‹æ–‡ + k ä¸ªè‰ç¨¿ tokenâ€ä¸Šè¿è¡Œä¸€æ¬¡ã€‚è¿™ä¼šä¸ºè¿™ `k` ä¸ªä½ç½®å¤–åŠ ä¸€ä¸ªé¢å¤–ä½ç½®äº§ç”Ÿæ¦‚ç‡ï¼ˆå› æ­¤å¾—åˆ° `k+1` ä¸ªå€™é€‰ï¼‰ï¼›
3. **Accept/Reject** ï¼šä»å·¦åˆ°å³éå†è¿™ `k` ä¸ªè‰ç¨¿ tokenï¼š
  - è‹¥å¤§æ¨¡å‹å¯¹è¯¥è‰ç¨¿ token çš„æ¦‚ç‡ â‰¥ è‰ç¨¿æ¨¡å‹çš„æ¦‚ç‡ï¼Œåˆ™æ¥å—å®ƒï¼›
  - å¦åˆ™ï¼Œä»¥ `p_large(token) / p_draft(token)` çš„æ¦‚ç‡æ¥å—å®ƒï¼›
  - åœ¨ç¬¬ä¸€æ¬¡æ‹’ç»å¤„åœæ­¢ï¼Œæˆ–è€…æ¥å—æ‰€æœ‰ `k` ä¸ªè‰ç¨¿ tokenï¼›
    - è‹¥æ‰€æœ‰ `k` ä¸ªè‰ç¨¿ token éƒ½è¢«æ¥å—ï¼Œè¿˜å¯ä»¥ä»å¤§æ¨¡å‹â€œå…è´¹â€é‡‡æ ·é¢å¤–çš„ç¬¬ `k+1` ä¸ª tokenï¼ˆå› ä¸ºæˆ‘ä»¬å·²ç»è®¡ç®—äº†è¯¥åˆ†å¸ƒï¼‰ã€‚
    - è‹¥å‘ç”Ÿäº†æ‹’ç»ï¼Œåˆ™åœ¨è¯¥ä½ç½®æ„é€ ä¸€ä¸ªé‡æ–°å¹³è¡¡çš„åˆ†å¸ƒï¼ˆ`p_large - p_draft`ï¼Œæœ€å°å€¼é’³åˆ¶ä¸º 0ï¼Œå¹¶å½’ä¸€åŒ–ä¸º 1ï¼‰ï¼Œå¹¶ä»ä¸­é‡‡æ ·æœ€åä¸€ä¸ª tokenã€‚

**Why this works**ï¼šå°½ç®¡æˆ‘ä»¬ä½¿ç”¨å°æ¨¡å‹æå‡ºå€™é€‰ï¼Œä½†accept/rejectè§„åˆ™ä¿è¯äº†åœ¨æœŸæœ›æ„ä¹‰ä¸Šï¼Œåºåˆ—çš„åˆ†å¸ƒä¸é€ token ä»å¤§å‹æ¨¡å‹é‡‡æ ·çš„ç»“æœå®Œå…¨ä¸€è‡´ã€‚è¿™æ„å‘³ç€ speculative decoding åœ¨ç»Ÿè®¡ä¸Šç­‰ä»·äºæ ‡å‡†çš„è‡ªå›å½’è§£ç ï¼Œä½†æ½œåœ¨è·å¾—æ›´å¿«çš„decodingé€Ÿåº¦ï¼Œå› ä¸ºä¸€æ¬¡å¤§å‹æ¨¡å‹çš„å‰å‘ä¼ æ’­å³å¯äº§å‡ºè‡³å¤š `k+1` ä¸ª tokenã€‚

vLLM V1 ä¸æ”¯æŒâ€œLLM draft modelâ€çš„æ–¹æ³•ï¼Œè€Œæ˜¯å®ç°äº†æ›´å¿«ä½†ç²¾åº¦è¾ƒä½çš„æè®®æ–¹æ¡ˆï¼š`n-gram`ã€`EAGLE` å’Œ `Medusa`ã€‚

ä¸‰è€…çš„ä¸€å¥è¯æ¦‚è¿°ï¼š
- `n-gram`ï¼šå–æœ€å `prompt_lookup_max` ä¸ª tokenï¼›åœ¨åºåˆ—ä¸­å¯»æ‰¾æ­¤å‰çš„åŒ¹é…ï¼›è‹¥æ‰¾åˆ°ï¼Œåˆ™æå‡ºç´§éšè¯¥åŒ¹é…ä¹‹åçš„ `k` ä¸ª tokenï¼›å¦åˆ™å‡å°çª—å£å¹¶é‡è¯•ï¼Œç›´åˆ° `prompt_lookup_min`ã€‚
- `EAGLE`ï¼šå¯¹ LLM åšä¸€æ¬¡ `â€œmodel surgeryâ€` ï¼Œä¿ç•™ embeddings ä¸ LM headï¼Œç”¨è½»é‡çº§ MLP æ›¿æ¢ transformer stackï¼›å°†å…¶å¾®è°ƒä¸ºä¸€ä¸ªå»‰ä»·draftã€‚
- `Medusa`ï¼šåœ¨å¤§å‹æ¨¡å‹çš„é¡¶ç«¯ï¼ˆembeddings before LM headï¼‰è®­ç»ƒ auxiliary linear headï¼Œç”¨äºå¹¶è¡Œé¢„æµ‹æ¥ä¸‹æ¥çš„ `k` ä¸ª tokenï¼›è¿™äº› head èƒ½æ¯”å•ç‹¬è¿è¡Œä¸€ä¸ªå° LM æ›´é«˜æ•ˆåœ°æå‡º token å€™é€‰ã€‚

åœ¨ vLLM ä¸­ä½¿ç”¨ `ngram` ä½œä¸ºè‰ç¨¿æ–¹æ³•æ¥è°ƒç”¨ speculative decoding çš„æ–¹å¼å¦‚ä¸‹ï¼š

```python
from vllm import LLM, SamplingParams

prompts = [
    "Hello, my name is",
    "The president of the United States is",
]

sampling_params = SamplingParams(temperature=0.8, top_p=0.95)

speculative_config={
    "method": "ngram",
    "prompt_lookup_max": 5,
    "prompt_lookup_min": 3,
    "num_speculative_tokens": 3,
}

def main():
    llm = LLM(model="TinyLlama/TinyLlama-1.1B-Chat-v1.0", speculative_config=speculative_config)

    outputs = llm.generate(prompts, sampling_params)

if __name__ == "__main__":
    main()
```

vLLM ä¸­çš„å·¥ä½œæ–¹å¼ï¼š

**è®¾ç½®é˜¶æ®µï¼ˆå¼•æ“æ„é€ æœŸé—´ï¼‰ï¼š**

1. **åˆå§‹åŒ–è®¾å¤‡**ï¼šåˆ›å»ºä¸€ä¸ª `drafter`ï¼ˆè‰ç¨¿æ¨¡å‹ï¼Œä¾‹å¦‚ `NgramProposer`ï¼‰å’Œä¸€ä¸ª `rejection_sampler`ï¼ˆå…¶éƒ¨åˆ†ä»£ç ç”¨ Triton ç¼–å†™ï¼‰ã€‚
2. **åŠ è½½æ¨¡å‹**ï¼šåŠ è½½è‰ç¨¿æ¨¡å‹æƒé‡ï¼ˆå¯¹ n-gram è€Œè¨€ä¸ºç©ºæ“ä½œï¼‰ã€‚

**åœ¨ `generate` å‡½æ•°ä¸­çš„åç»­æ­¥éª¤ï¼ˆå‡è®¾æ”¶åˆ°å…¨æ–°è¯·æ±‚ï¼‰ï¼š**

1. ç”¨å¤§æ¨¡å‹è¿è¡Œå¸¸è§„çš„ prefill æ­¥éª¤ã€‚
2. å‰å‘ä¼ æ’­å’Œæ ‡å‡†é‡‡æ ·åï¼Œè°ƒç”¨ `propose_draft_token_ids(k)` ä» draft model é‡‡æ · `k` ä¸ªè‰ç¨¿ tokenã€‚
3. å°†è¿™äº›å­˜å‚¨åœ¨ `request.spec_token_ids` ä¸­ï¼ˆæ›´æ–°è¯·æ±‚metadataï¼‰ã€‚
4. åœ¨ä¸‹ä¸€ä¸ª engine step ä¸­ï¼Œå½“è¯·æ±‚å¤„äºè¿è¡Œé˜Ÿåˆ—æ—¶ï¼Œå°† `len(request.spec_token_ids)` åŠ åˆ°"æ–° token"è®¡æ•°ä¸­ï¼Œä»¥ä¾¿ `allocate_slots` ä¸ºå‰å‘ä¼ æ’­é¢„ç•™è¶³å¤Ÿçš„ KV å—ã€‚
5. å°† `spec_token_ids` å¤åˆ¶åˆ° `input_batch.token_ids_cpu` ä¸­ï¼Œå½¢æˆï¼ˆä¸Šä¸‹æ–‡ + è‰ç¨¿ï¼‰tokenã€‚
6. é€šè¿‡ `_calc_spec_decode_metadata` è®¡ç®—metadataï¼ˆä» `input_batch.token_ids_cpu` å¤åˆ¶ tokenï¼Œå‡†å¤‡ logits ç­‰ï¼‰ï¼Œç„¶ååœ¨è‰ç¨¿ token ä¸Šè¿è¡Œå¤§æ¨¡å‹å‰å‘ä¼ æ’­ã€‚
7. ä¸ä½¿ç”¨å¸¸è§„çš„ logits é‡‡æ ·ï¼Œè€Œæ˜¯ç”¨ `rejection_sampler` ä»å·¦åˆ°å³æ¥å—/æ‹’ç»å¹¶äº§ç”Ÿ `output_token_ids`ã€‚
8. é‡å¤æ­¥éª¤ 2-7ï¼Œç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ã€‚

ç†è§£è¿™ä¸€è¿‡ç¨‹çš„æœ€ä½³æ–¹å¼æ˜¯å¯åŠ¨è°ƒè¯•å™¨å¹¶é€æ­¥æ‰§è¡Œä»£ç åº“ï¼Œä½†æœ¬èŠ‚å¸Œæœ›èƒ½è®©ä½ å¯¹æ­¤æœ‰æ‰€äº†è§£ã€‚

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-11.png)

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-12.png)

## Disaggregated P/D

æˆ‘æ­¤å‰å·²ç»æåˆ°è¿‡è¿›è¡Œ P/Dï¼ˆprefill/decodeï¼‰è§£è€¦çš„åŠ¨æœºã€‚

åœ¨å®é™…æ¨ç†ç”Ÿäº§è¿‡ç¨‹ä¸­ï¼Œ`prefill` ä¸ `decode` å…·æœ‰æˆªç„¶ä¸åŒçš„æ€§èƒ½ç”»åƒï¼ˆå‰è€…æ›´åè®¡ç®—å—é™ compute-boundï¼Œåè€…æ›´åå†…å­˜å¸¦å®½å—é™ memory-bandwidth-boundï¼‰ï¼Œå› æ­¤å°†å®ƒä»¬çš„æ‰§è¡Œæ‹†åˆ†æ˜¯ä¸€ä¸ªåˆç†çš„è®¾è®¡ã€‚è¿™èƒ½æ›´ç´§è‡´åœ°æ§åˆ¶å»¶è¿Ÿâ€”â€”åŒ…æ‹¬ `TFTT`ï¼ˆtime-to-first-tokenï¼‰ä¸ `ITL`ï¼ˆinter-token latencyï¼‰ï¼Œå…¶ç»†èŠ‚åœ¨åŸºå‡†æµ‹è¯•ç« èŠ‚ä¼šè¿›ä¸€æ­¥å±•å¼€ã€‚

åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬ä¼šè¿è¡Œ `N` ä¸ª vLLM prefill å®ä¾‹ä¸ `M` ä¸ª vLLM decode å®ä¾‹ï¼Œå¹¶æ ¹æ®å®æ—¶è¯·æ±‚çš„æ··åˆæƒ…å†µè¿›è¡Œè‡ªåŠ¨æ‰©ç¼©ã€‚Prefill worker ä¼šå°† KV å†™å…¥ä¸€ä¸ªä¸“ç”¨çš„ KV-cache æœåŠ¡ï¼›decode worker åˆ™ä»ä¸­è¯»å–ã€‚è¿™æ ·å¯ä»¥å°†é•¿ä¸”çªå‘çš„ prefill ä¸ç¨³å®šã€å¯¹å»¶è¿Ÿæ•æ„Ÿçš„ decode æœ‰æ•ˆéš”ç¦»ã€‚

é‚£ä¹ˆåœ¨ vLLM ä¸­å¦‚ä½•å®ç°ï¼Ÿä¸ºä¾¿äºè¯´æ˜ï¼Œä¸‹é¢çš„ç¤ºä¾‹ä½¿ç”¨ `SharedStorageConnector`ï¼šè¿™æ˜¯ä¸€ä¸ªç”¨äºå±•ç¤ºæœºåˆ¶ç»†èŠ‚çš„è°ƒè¯•å‹ connector å®ç°ã€‚å…¶ä¸­`Connector` æ˜¯ vLLM ç”¨äºåœ¨å®ä¾‹ä¹‹é—´äº¤æ¢ KV çš„æŠ½è±¡ã€‚`Connector` æ¥å£ç›®å‰å°šä¸ç¨³å®šï¼ŒçŸ­æœŸå†…è®¡åˆ’è¿›è¡Œä¸€äº›æ”¹è¿›ï¼Œè¿™äº›æ”¹åŠ¨å¯èƒ½åŒ…å«ä¸å…¼å®¹çš„å˜æ›´ã€‚

æˆ‘ä»¬ä¼šå¯åŠ¨ä¸¤ä¸ª vLLM å®ä¾‹ï¼ˆ`GPU 0` ç”¨äº prefillï¼Œ`GPU 1` ç”¨äº decodeï¼‰ï¼Œç„¶ååœ¨å®ƒä»¬ä¹‹é—´ä¼ è¾“ KV cacheï¼š

```python

import os
import time
from multiprocessing import Event, Process
import multiprocessing as mp

from vllm import LLM, SamplingParams
from vllm.config import KVTransferConfig

prompts = [
    "Hello, my name is",
    "The president of the United States is",
]

def run_prefill(prefill_done):
  os.environ["CUDA_VISIBLE_DEVICES"] = "0"

  sampling_params = SamplingParams(temperature=0, top_p=0.95, max_tokens=1)

  ktc=KVTransferConfig(
      kv_connector="SharedStorageConnector",
      kv_role="kv_both",
      kv_connector_extra_config={"shared_storage_path": "local_storage"},
  )

  llm = LLM(model="TinyLlama/TinyLlama-1.1B-Chat-v1.0", kv_transfer_config=ktc)
  llm.generate(prompts, sampling_params)

  prefill_done.set()  # notify decode instance that KV cache is ready

  # To keep the prefill node running in case the decode node is not done;
  # otherwise, the script might exit prematurely, causing incomplete decoding.
  try:
      while True:
          time.sleep(1)
  except KeyboardInterrupt:
      print("Script stopped by user.")

def run_decode(prefill_done):
  os.environ["CUDA_VISIBLE_DEVICES"] = "1"

  sampling_params = SamplingParams(temperature=0, top_p=0.95)

  ktc=KVTransferConfig(
      kv_connector="SharedStorageConnector",
      kv_role="kv_both",
      kv_connector_extra_config={"shared_storage_path": "local_storage"},
  )

  llm = LLM(model="TinyLlama/TinyLlama-1.1B-Chat-v1.0", kv_transfer_config=ktc)

  prefill_done.wait()  # block waiting for KV cache from prefill instance

  # Internally it'll first fetch KV cache before starting the decoding loop
  outputs = llm.generate(prompts, sampling_params)

if __name__ == "__main__":
  prefill_done = Event()
  prefill_process = Process(target=run_prefill, args=(prefill_done,))
  decode_process = Process(target=run_decode, args=(prefill_done,))

  prefill_process.start()
  decode_process.start()

  decode_process.join()
  prefill_process.terminate()
```

vLLM ä¸­çš„æ­¥éª¤å¦‚ä¸‹ï¼š

1. å®ä¾‹åŒ–ï¼ˆå¼•æ“æ„é€ æœŸé—´ï¼‰, connector ä¼šåœ¨ä¸¤ä¸ªåœ°æ–¹è¢«åˆ›å»ºï¼š
  - åœ¨ worker çš„è®¾å¤‡åˆå§‹åŒ–æµç¨‹ä¸­ï¼ˆ`init_worker_distributed_environment` ä¸‹ï¼‰ï¼Œä»¥è§’è‰² "worker" åˆ›å»º connectorï¼›
  - åœ¨ scheduler çš„æ„é€ å‡½æ•°ä¸­ï¼Œä»¥è§’è‰² "scheduler" åˆ›å»º connectorï¼›
2. Cache æŸ¥æ‰¾ï¼šå½“ scheduler ä»ç­‰å¾…é˜Ÿåˆ—å¤„ç† prefill è¯·æ±‚ï¼ˆåœ¨æœ¬åœ° prefix-cache æ£€æŸ¥ä¹‹åï¼‰ï¼Œä¼šè°ƒç”¨ connector çš„ `get_num_new_matched_tokens`ï¼Œä»¥æ£€æµ‹ KV-cache æœåŠ¡ä¸­æ˜¯å¦å­˜åœ¨å¤–éƒ¨ç¼“å­˜çš„ tokenã€‚prefill åœºæ™¯ä¸‹è¯¥å€¼å§‹ç»ˆä¸º 0ï¼›decode åœºæ™¯ä¸‹å¯èƒ½å‘½ä¸­ã€‚ç»“æœä¼šåœ¨è°ƒç”¨ `allocate_slots` ä¹‹å‰åŠ åˆ°æœ¬åœ°è®¡æ•°ä¸­ï¼›
3. çŠ¶æ€æ›´æ–°ï¼šscheduler éšåè°ƒç”¨ `connector.update_state_after_alloc`ï¼Œè®°å½•å‘½ä¸­ cache çš„è¯·æ±‚ï¼ˆå¯¹ prefill è€Œè¨€æ˜¯ no-opï¼‰ï¼›
4. metadataæ„å»ºï¼šåœ¨è°ƒåº¦æœ«å°¾ï¼Œscheduler è°ƒç”¨ `meta = connector.build_connector_meta`ï¼š
    - prefill å°†æ‰€æœ‰ `is_store=True` çš„è¯·æ±‚åŠ å…¥ï¼ˆç”¨äºä¸Šä¼  KVï¼‰ï¼›
    - decode å°†æ‰€æœ‰ `is_store=False` çš„è¯·æ±‚åŠ å…¥ï¼ˆç”¨äºè·å– KVï¼‰ï¼›
5. Context Managerï¼šåœ¨å‰å‘ä¼ æ’­ä¹‹å‰ï¼Œengine è¿›å…¥ä¸€ä¸ª KV-connector çš„ context managerï¼š
    - è¿›å…¥æ—¶ï¼šè°ƒç”¨ `kv_connector.start_load_kv`ï¼Œå¯¹ decode è€Œè¨€ï¼Œå®ƒä¼šä»å¤–éƒ¨æœåŠ¡å™¨åŠ è½½ KV å¹¶æ³¨å…¥åˆ°åˆ†é¡µå†…å­˜ï¼›å¯¹ prefill è€Œè¨€æ˜¯ no-opï¼›
    - é€€å‡ºæ—¶ï¼šè°ƒç”¨ `kv_connector.wait_for_save`ï¼Œå¯¹ prefill è€Œè¨€ï¼Œå®ƒä¼šé˜»å¡ç›´è‡³ KV ä¸Šä¼ åˆ°å¤–éƒ¨æœåŠ¡å™¨ï¼›å¯¹ decode è€Œè¨€æ˜¯ no-opã€‚

ä¸‹å›¾ç»™å‡ºä¸€ä¸ªå¯è§†åŒ–ç¤ºä¾‹ï¼š

![](https://raw.githubusercontent.com/kakack/kakack.github.io/master/_images/250715-13.png)

- å¯¹äº `SharedStorageConnector`ï¼Œæ‰€è°“çš„â€œexternal serverâ€å…¶å®åªæ˜¯æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿã€‚
- ä¾æ®é…ç½®ï¼ŒKV ä¹Ÿå¯ä»¥æŒ‰å±‚è¿›è¡Œä¼ è¾“ï¼ˆåœ¨æ¯ä¸ªæ³¨æ„åŠ›å±‚å‰/åè¿›è¡ŒåŠ è½½/ä¿å­˜ï¼‰ã€‚
- `decode` ä»…åœ¨å…¶è¯·æ±‚çš„ç¬¬ä¸€æ­¥åŠ è½½ä¸€æ¬¡å¤–éƒ¨ KVï¼›ä¹‹åä¾¿åœ¨æœ¬åœ°è¿›è¡Œè®¡ç®—ä¸å­˜å‚¨ã€‚

# From UniprocExecutor to MultiProcExecutor

# Distributed system serving vLLM

## On the headless server node

## On the API server node

# Benchmarks and auto-tuning - latency vs throughput

# Epilogue

# Acknowledgements

A huge thank you to Hyperstack for providing me with H100s for my experiments over the past year!

Thanks to Nick Hill (core vLLM contributor, RedHat), Mark Saroufim (PyTorch), Kyle Krannen (NVIDIA, Dynamo), and Ashish Vaswani for reading pre-release version of this blog post and providing feedback!

References
vLLM https://github.com/vllm-project/vllm
"Attention Is All You Need", https://arxiv.org/abs/1706.03762
"Efficient Memory Management for Large Language Model Serving with PagedAttention", https://arxiv.org/abs/2309.06180
"DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model", https://arxiv.org/abs/2405.04434
"Jenga: Effective Memory Management for Serving LLM with Heterogeneity", https://arxiv.org/abs/2503.18292
"Orca: A Distributed Serving System for Transformer-Based Generative Models", https://www.usenix.org/conference/osdi22/presentation/yu
"XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models", https://arxiv.org/abs/2411.15100
"Accelerating Large Language Model Decoding with Speculative Sampling", https://arxiv.org/abs/2302.01318
"EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty", https://arxiv.org/abs/2401.15077
"Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads", https://arxiv.org/abs/2401.10774
LMCache, https://github.com/LMCache/LMCache

