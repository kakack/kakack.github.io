---

layout: post
tags: [Deep Learning, Large Language Model, NLP]
title: New Era of Large Language Models
date: 2023-11-10
author: Kaka Chen
comments: true
toc: true
pinned: false

---

随着人们通过在大规模语料库上对`transformer`模型进行预训练得到了预训练语言模型（Pre-training Language Model, PLM），在自然语言处理（Natural Language Processing， NLP）任务上展现出了无与伦比的表现。同时随着参数量进一步增长到更大规模，这些模型性能更是得到显著增长同时表现出了很多原有小尺寸模型不具备的能力，为了区别不同参数规模下的语言模型，于是这一类包含数百亿以上规模参数的PLM被称为`大语言模型（Large Language Model, LLM）`，其中当前声名鹊起的`ChatGPT`就隶属于这一类模型。

---
# Abstract

语言建模（LM）是提高机器语言智能的主要方法之一，通常旨在对词序列的生成概率进行建模，以预测未来（或缺失）token的概率。这一块领域的研究根据不通模型类型的迭代演进，可以分为四个主要阶段：

## 1. 统计语言模型(Static Language Model)

本质是基于马尔科夫假设建立词预测模型，根据最近的上下文预测下一个词

# Pre-Training

# Adaptation Tuning

# Utilization

# Capacity Evaluation

# Future