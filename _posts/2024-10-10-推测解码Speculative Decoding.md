---

layout: post
tags: [LLM, NLP]
title: 推测解码Speculative Decoding
date: 2024-10-10
author: Kyrie Chen
comments: true
toc: true
pinned: false

---

推测解码（Speculative Decoding）是一种大模型的推理加速方式。
传统的解码方式需要逐步调用大模型自回归地预测每个单词，耗时较长。推测解码使用某种方法，先生成一系列草稿tokens，将这些草稿作为候选序列传入大模型，然后由大模型在单次前向传播中验证这些候选序列是否符合其高质量生成标准。因此，推测解码分为“草稿”和“验证”两个串行阶段。
这使得大模型避免了逐个token推理的过程，大幅减少计算时间，同时保留了生成的连贯性和准确性。如果利用得当，推测解码可以在不牺牲大模型生成质量的情况下，大幅增加大模型的解码速度。
分类
目前的推测解码（Speculative Decoding）方法可以大致分为3类：
- 在内存中同时加载一个小草稿模型，辅助生成草稿（最初的 Speculative Decoding 论文提出的方法）。这个小草稿模型可以是同系列的参数更小的模型，也可能是额外训练的轻量级模块。这些方法在1.1节中介绍。
- 直接将大模型同时作为起草模型和验证模型。这种方法往往会对原始模型结构做一些修改，或使用额外数据再微调大模型。这些方法在1.2节中介绍。
- 从外部数据中（如外部数据库或 prompt）检索获取草稿来源。这些方法在1.3节中介绍。